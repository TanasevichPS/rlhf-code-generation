How to plot maximal intensity projection of images in same directory. I have a Z-stack of images of biological samples. Each biological sample is saved in its own directory : Sample_1, Sample_2... Each image of the Z-stack is saved alone : Sample_1/position_1.tif, Sample_1/position_2.tif, Sample_1/position_3.tif... How can I plot with opencv (or any other python library) the maximal intensity projection of each biological sample ? I found here (Maximum intensity projection from image stack) an answer that is close but my original images are not stacks but separated images. Please, could you let me know if you have any clue in order to solve my issue ? 	\n  How can I plot with opencv (or any other python library) the maximal intensity projection of each biological sample?	\nI have a Z-stack of images of biological samples. Each biological sample is saved in its own directory : Sample_1, Sample_2... Each image of the Z-stack is saved alone : Sample_1/position_1.tif, Sample_1/position_2.tif, Sample_1/position_3.tif... How can I plot with opencv (or any other python library) the maximal intensity projection of each biological sample? I found here (Maximum intensity projection from image stack) an answer that is close but my original images are not stacks but separated images. Please, could you let me	1
How to create a class that is not an instance of type?. According to 3.3.3.2. Resolving MRO entries:  If a base that appears in class definition is not an instance of type, then an _mro_entries_ method is searched on it.  So, I suppose there should be a way to create a class that is not an instance of type. But how? I know only two ways in Python to create a class:  A class definition (class MyClass(...): ...) creates an instance of type or the given metaclass given by the metaclass argument (actually, the most derived one from the set including the metaclasses of the bases). A call of type(name, bases, dict) creates an instance of type.  Is there any other way? How to create a class that is not an instance of type? 	_ _.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__	If you are developing the classes yourself, a more proper object - oriented style is to define methods on the classes that encapsulate a particular behaviour, instead of checking the object ’ s class and doing a different thing based on what class it is. for example, if you have a function that does something: def search ( obj ) : if isinstr(isinstr(isinstr(isinstr(isinstr(isinstr(isinst	1
how can i stop showing the decimal .0 after the whole number? python. So, i entered code below to round a column to the nearest integer, though it still shows up with decimals. Eg. I want to round 62.040 to just 62 though once the code is entered it shows 62.0 in the output data['Final'] = np.ceil(data['Total'].round()) 	' '( bpo - 8257 ). mixed type comparisons are now fully supported so that decimal objects can be directly compared with float and fractions. fraction ( bpo - 2531 and bpo - 8188 ). similar changes were made to fractions. fraction so that the from _ float ( ) and from _ decimal ( ) methods are no longer needed ( bpo - 8294 ).	' '##94 therefore the best possible approximation to 1 / 10 in 754 double precision is : 7205759403792794 / 2 * * 56 dividing both the numerator and denominator by two reduces the fraction to : 3602879701896397 / 2 * * 55 Note that since we rounded up, this is actually a little bit larger than 1 / 10 ; if we had not rounded up, the quotient would have been a little bit larger than 1 / 10 ; if	1
Get nodes within 1km walking distance of a GPS location OSMNX. Given a (lat,lng) point and an all type OSMNX network, how can I find which nodes in the graph are within 1km walking distance from the point? I was thinking about calculating the great circle distance between each node and the point and checking whether it is at most 1km, but I do not believe this will be very accurate since the topology of the network will be ignored. 	' '( fullcircle = 360. 0 )  parameters fullcircle – a number set angle measurement units, i. e. set number of “ degrees ” for a full circle. default value is 360 degrees. &gt;&gt;&gt; turtle. home ( 90) &gt;&gt;&gt; turtle. heading ( 90) &gt;&gt;&gt; turtle. heading ( 90) &gt;&gt;&gt; turtle.	' 'once those are marked as processed by calling topologicalsorter. done ( ), further calls will return all new nodes that have all their predecessors already processed. once no more progress can be made, empty tuples are returned. raises valueerror if called without calling prepare ( ) previously.''once those are marked as processed by calling topologicalsorter. done ( ), further calls will return all new nodes that have all their predecessors already processed. once no more progress can be made, empty tuples are returned. raises valueerror	1
Method of opening .py scripts without packages installed? (pip). Essentially want to send a script to my friend to go over. He has python installed on his computer, but doesn't specifically have 'pyinputplus' - a key component of the program. Is there a way that I can send this script to him without him installing pyinputplus? Or whether I can effectively insert 'pip install pyinputplus' into the code and have it execute when he runs it? I had also considered making the script an executable, but didn't think that would help. Relatively new to this, so apologies for my naivety. Thanks. 	\nI think the answer is yes, but I'm not sure. I would recommend that you use a virtualenv to install the packages you want to use. Then you can simply run the script with the virtualenv.\n\nA:\n\nYou can use the virtualenv to install packages.\n\nA:\n\nYou can use virtualenv to install packages.\n\nA:\n\nYou can use virtualenv to install packages.\n\nA:\n\nYou can use virtualenv to install packages.\n\nA:\n\nYou can use virtualenv to install packages.\n\nA:\n\nYou can	' '##lib. resources in python 3. 7 and newer ( backported as importlib _ resources for older versions of python ), this can eliminate the need to use the older and less efficient pkg _ resources package.	0
Is there a way to set a float for the single step of a pyqt5 scrollbar?. I'm trying to use a scroll bar in a pyqt5 gui. I need it to increment by 0.01 (Total length should be around 390) for a single click on the arrow but it seems like the setSingleStep only takes integers. Is there a way to make a single step 0.01? 	\n  I'm trying to use a scroll bar in a pyqt5 gui. I need it to increment by 0.01 (Total length should be around 390) for a single click on the arrow but it seems like the setSingleStep only takes integers. Is there a way to make a single step 0.01?	You can use auto-numbering and named fields, as in the second example above. ( contributed by eric smith ; bpo - 5237. ) complex numbers now correctly support usage with format ( ), and default to being right - aligned. specifying a precision or comma - separation applies to both the real and imaginary parts of the number, but a specified field width and alignment is applied to the whole of the resulting 1. 5 + 3j output. ( contributed by eric smith ; bpo -	0
"""get a list from a list `lst` with values mapped into a dictionary `dct`"""	\n\nimport re\n\nfrom collections import defaultdict\n\nfrom. import _base\nfrom. import _base_dict\nfrom. import _base_list\nfrom. import _base_list_dict\nfrom. import _base_list_list\nfrom. import _base_list_list_dict\nfrom. import _base_list_list_dict_dict\nfrom. import _base_list_list_dict_list\nfrom. import _base_list_list_dict_list_dict\nfrom. import _base_list_list_dict_list_dict_list	\n     return {k: v for k, v in zip(lst, dct)}	1
"""split a list in first column  into multiple columns keeping other columns as well in pandas data frame"""	\n\nimport pandas as pd\nimport numpy as np\n\n	\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport argparse\nimport re\nimport glob\nimport shutil\nimport csv\nimport time\n\n	1
Method of opening .py scripts without packages installed? (pip). Essentially want to send a script to my friend to go over. He has python installed on his computer, but doesn't specifically have 'pyinputplus' - a key component of the program. Is there a way that I can send this script to him without him installing pyinputplus? Or whether I can effectively insert 'pip install pyinputplus' into the code and have it execute when he runs it? I had also considered making the script an executable, but didn't think that would help. Relatively new to this, so apologies for my naivety. Thanks. 	' 'directory ” will have precedence over the one next to the executable, so a user, who may not have write access to the. ini file next to the launcher, can override commands in that global. ini file.	The python launcher for windows is a utility which aids in locating and executing of different python versions. it allows scripts ( or the command - line ) to indicate a preference for a specific python version, and will locate and execute that version. unlike the path variable, the launcher will correctly select the most appropriate version of python. it will prefer per - user installations over system - wide ones, and orders by language version.	1
Why is 5D in hex represented as bytearray(b']')?. For example if you represent 5D in a bytearray you get bytearray(b']'), but I don't understand why. Is it because of ASCII and if so, how is Python handling all the ASCII Characters? 	' 'a number : > > > oct ( 42 )'052'> > > future _ builtins. oct ( 42 )'0o52'> > > bin ( 173 )'0b10101101'the int ( ) and long ( ) builtins will now accept the “ 0o ” and “ 0b ” prefixes when base - 8 or base - 2 are requested, or when the base argument is zero ( signalling that the base used should be determined from	The mutable type is based on collections. The mutable api is based on collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collections.collect	0
Build Flask App that fetch data from postgres database without page reload. I have a flask web app that shows data from sqlalchemy to the user. I want the app to fetch any new data when it is added to the database automatically without further ado from the client-side (something like news feeds). How do I achieve that. I know that I should use socket.io but don't know-how. All examples in google are about chat app. It would be very helpful if somebody could give me the roadmap to do it. The front end in js and the backend is in flask python. any help will be appreciated! Thanks 	' '. contextmanager. patch by siddharth velankar. bpo - 26187 : test that sqlite3 trace callback is not called multiple times when schema is changing. indirectly fixed by switching to use sqlite3 _ prepare _ v2 ( ) in bpo - 9303. patch by aviv palivoda. bpo - 30017 : allowed calling the close ( ) method of the zip entry writer object multiple times. writing to a closed writer now always produces.	uwsgi and gunicorn have a built-in function that can be used to handle client requests. If you want to use a file - based handler, you can use the uwsgi module to do the work for you: https://docs.python.org/3/library/uwsgi.html#uwsgi.executor	1
How to save the moving graphs in the jupyter notebook into the pdf?. I have tried saving the notebook which has moving graphs in form of pdf but the pdf doesn't show any moving graphs, is it possible to save the moving graphs in form of pdf? 	''in simulated shells, such as those presented by idle and other development environments. This is described in pep 264. ( contributed by michael hudson.) The new license introduced with python 1. 6 wasn ’ t gpl - compatible. this is fixed by some minor textual changes to the 2. 2 license, so it ’ s now legal to embed python inside a gpled program again. Note that python itself is not gpled, but instead is	\n\nYou can save the notebook as a pdf by using the save as pdf button in the notebook.\n\nYou can also save the notebook as a pdf by using the save as pdf button in the notebook.\n\nYou can also save the notebook as a pdf by using the save as pdf button in the notebook.\n\nYou can also save the notebook as a pdf by using the save as pdf button in the notebook.\n\nYou can also save the notebook as a pdf by using the save as pdf button in the notebook.\n\nYou can also save the notebook as a pdf by using the save as pdf button in	1
How to stop a thread and restart it - python. How can I stop a thread from running and then restart it when called, havent been able to get a solid answer on this. Thanks in advance. 	' '##ask ( 2 ) and pthread _ sigmask ( 3 ) for further information. see also pause ( ), sigpending ( ) and sigwait ( ). new in version 3. 3. signal. setitimer ( which, seconds, interval = 0. 0 ) sets given interval timer ( one of signal. itimer _ real, signal. itimer _ virtual or signal. itimer _ prof ) specified by which to fire after seconds (	' '##le ( ) no longer computes the repr of unknown objects to display in an error message, to protect against badly behaved custom reprs. bpo - 30768 : fix the pthread + semaphore implementation of pythread _ acquire _ lock _ timed ( ) when called with timeout > 0 and intr _ flag = 0 : recompute the timeout if sem _ timedwait ( ) is interrupted by a signal ( eintr	1
How can I change my default Python version, that if I type python in the terminal python 3 gets executed?. Can somebody help me? I tried to change my python version with the alias but I got a permission denied. What can I do? I'm on a mac. 	\n  I tried to change my python version with the alias but I got a permission denied. What can I do?	sys. exec _ prefix'/ usr' is a placeholder for the version of python, for example 3. 2 ; abiflags will be replaced by the value of sys. abiflags or the empty string for platforms which don ’ t define abi flags ; dist. sys. exec _ prefix'/ usr'	1
Getting connected partitions using METIS. I am using Metis on Python to partition a networkx graph I have. My objective is to get partitions that have an almost equal sum of node weights, which Metis does perfectly. However, a constraint I want to respect is that nodes in the same partition should be connected (have edges in common), which Metis doesn't do. Is there a way or a parameter to ensure that? 	if the separator isn't found, the first element of the string is the first element of the string. if the separator isn't found, the first element of the string is the first element of the string. if the separator isn't found, the first element of the string is the first element of the string. if the separator isn't found, the first element of the string is the first element of the string. if the separator isn't found, the first element of the string	' '( ), sub ( ), mul ( ), floordiv ( ), abs ( ),... logical operations : not _ ( ), truth ( ). bitwise operations : and _ ( ), or _ ( ), invert ( ). comparisons : eq ( ), ne ( ), lt ( ), le ( ), gt ( ), and ge ( ). object identity : is _ ( ), is _ not ( ).	1
Is there a way to not have to specify the user when connecting with psycogp2?. So just passing in the host and db name and not having to specify the user like: host=blabla.co port=7000 dbname=ff_db instead of: host=blabla.co port=7000 dbname=ff_db user=some_user The .pgpass file already has the user specified so I feel passing this in is redundant. 	\nYes, you can use the pgpass file to specify the user. \nYou can use the pgpass file to specify the user, but you can't use the pgpass file to specify the host. \nYou can use the pgpass file to specify the host, but you can't use the pgpass file to specify the dbname. \nYou can use the pgpass file to specify the dbname, but you can't use the pgpass file to specify the user. \nYou can use the pgpass file to specify the user, but you can't use the pgpass file to specify the host	imap4. uid ( command, arg [,... ] )  execute command args with messages identified by uid, rather than message number. returns response appropriate to command. at least one argument must be supplied ; if none are provided, the server will return an error and an exception will be raised. imap4. unsubscribe ( mailbox )  unsubscribe from old mailbox.	0
"""create a list containing each two adjacent letters in string `word` as its elements"""	\n     return [word[i:i+2] for i in range(len(word)-1)]\n\n	\n\nimport re\n\nfrom.. import util\nfrom.. import util.compat\nfrom.. import util.compat.string_types\nfrom.. import util.compat.string_types.string_types\nfrom.. import util.compat.string_types.string_types_base\nfrom.. import util.compat.string_types.string_types_base.string_types\nfrom.. import util.compat.string_types.string_types_base.string_types_base\nfrom.. import util.compat.string_types.string_types_base	0
How to Use "Pythonic" YOLOv5 from PyTorch. I'm interested in training a YOLOv5 model. Currently, I'm using Roboflow to annotate and export the data into YOLOv5 format. I'm also using Roboflow's Colab Notebook for YOLOv5. However, I'm not familiar with many of the commands used in the Roboflow Colab Notebook. I found on here that there appears to be a much more Pythonic way of using and manipulating the YOLOv5 model, which I would be much more familiar with. My questions regarding this are as follows:  Is there an online resource that can show me how to train the YOLOv5 and extract results after importing the model from PyTorch with the Pythonic version (perhaps a snippet of code right here on StackOverflow would help)? The official documentation that I could find (here) also uses the non-Pythonic method for the model. Is there any important functionality I would lose if I were to switch to this Pythonic method of using YOLOv5? I found nothing in the documentation that suggests otherwise, but would I need to export my data in a different format from Roboflow for the data to be able to train the Pythonic model? Similar to question 1), is there anywhere that can guide me how to use the trained model on test images? Do I simply do prediction=model(my_image.jpg)? What if I want predictions on multiple images at once?  Any guidance would be appreciated. Thanks! 	' 'documentation strings. the first line should always be a short, concise summary of the object ’ s purpose. for brevity, it should not explicitly state the object ’ s name or type, since these are available by other means ( except if the name happens to be a verb describing a function ’ s operation ). this line should begin with a capital letter and end with a period. if there are more lines in the documentation string, the second line should be blank, visually separating the summary.	\n  Is there an online resource that can show me how to train the YOLOv5 and extract results after importing the model from PyTorch with the Pythonic version (perhaps a snippet of code right here on StackOverflow would help)?	1
Generating uniform random numbers between two large integers in fortran90/95 or Python. I want to generate some uniform random numbers between [2E16, 5E20] in fortran90/95 or Python. I know that if R is a random number between zero and one (0R1), we can transform R to [A, B] as: R = (b-a)*r + a. But when I use this algorithm to generate some random numbers between [2E16, 5E20], most of generated random numbers are very close to 5E20. I know why this is occurred, it is because of that, the term B-A is approximately equal to B (because B is so bigger than A), and most of the generated random numbers are placed within the magnitude of B or B/10 (I mean it was very close to B). How can I solve this problem? One solution that I tried to apply is that, I split the [2E16, 5E20] interval into smaller intervals, such as: [2e16, 2e17], [2e17, 2e18], [2e18, 2e19], [2e19, 2e20], [2e20, 5e20]. And I generated some random numbers between each of the above intervals. Is there any other solutions? Is my solution correct? 	The random module now uses a new algorithm, the mersenne twister, implemented in c. it ’ s faster and more extensively studied than the previous algorithm. ( all changes contributed by raymond hettinger) the random module now uses a new algorithm, the mersenne twister, implemented in c. it ’ s faster and more extensively studied than the previous algorithm.	\n  I know why this is occurred, it is because of that, the term B-A is approximately equal to B (because B is so bigger than A), and most of the generated random numbers are placed within the magnitude of B or B/10 (I mean it was very close to B). How can I solve this problem?	1
How can I classify a dataset after one-hot encoding the target class?. I want to Classify a dataset with kernel machine. The Target-Class has 5 different values and I want to one-hot encoding it. After that I have 5 Target-Columns. I do the Training 5 times, one time per Target-Column. Now I want to classify a new sample. I classify the Sample 5 times using the 5 Trainig-model I got. At the end I look which Prediction has the maximum value over the 5 predictions and then I classify the sample according to the Class with the maximum prediction. I am not sure that I am doing the right thing. How can I do that in the right way? 	' '( self ) :... return list ( self. keylist )...	\n\nYou can use the following code to do that:\n\n	1
PyCharm Code Completion for files outside project directory. my python application imports other python packages in other locations on the filesystem dynamically at runtime. It then calls certain functions in these packages and supplies data objects from the main application. The issue is that coding these external packages there is no code completion in regard to the main apps code. Because these data objects are only supplied at runtime, as are their classes (which are already imported by then main app when calling the package) the package itself cannot reference them in any way (circular import). Since the package doesnt know about the objects up until it's running, Code Completion can't suggest any methods of these objects for example either. Is there any way for me to provide PyCharms Code Completion with a reference to the main application, so it can autocomplete my code? By this I mean suggestions for objects of the classes of my main app, autocomplete for native python packages works fine of course. The packages are imported by dynamically adding their path to the path variable, I tried to also add them to the interpreter path, however this did not work. 	' 'is being used as part of the build process for python. This changes a lot of relative locations for files, allowing them to be located in the build area rather than in an installed python.''is being used as part of the build process for python. This changes a lot of relative locations for files, allowing them to be located in the build area rather than in an installed python.	' '3. 9 : use bdist _ wheel ( wheel packages ) instead. builds a windows installer (. msi ) binary package. 9. 30. distutils. command. bdist _ rpm — build a binary distribution as a redhat rpm and srpm  9. 31. distutils. command. sdist — build a source distribution  9. 32. distutils. command. build — build all files of a package  9. 32	1
How to automate the process of running an excel model, 100,000 times, with different inputs in Python?. So I have a complex financial model on excel for a given set of input. Now I want to run the same model on 100,000 other sets of input and save it. Is there any libraries I should look into? I just have to change the inputs. Any guidance will be appreciated. TIA! 	' '( ) method on complex objects. ( removed by meador inge and mark dickinson ; bpo - 5211. ) the str. format ( ) method now supports automatic numbering of the replacement fields. This makes using str. format ( ) more closely resemble using % s formatting.	You can use auto-numbering and named fields, as in the second example above. ( contributed by eric smith ; bpo - 5237. ) complex numbers now correctly support usage with format ( ), and default to being right - aligned. specifying a precision or comma - separation applies to both the real and imaginary parts of the number, but a specified field width and alignment is applied to the whole of the resulting 1. 5 + 3j output. ( contributed by eric smith ; bpo -	1
Deleting Excess Rows in Python with Pandas. I have a python script that restructures our organization's data into a different shape using python's pylightxl. But this script only works with excel files with less than 5000 rows of data, which is the standard format. But some files go up to 65000 rows, with unnecessary data after the 5000 index. What i want is to delete the excess rows after 5000th index. Pylightxl cannot do this. Only pandas can, I've scoured the internet on deleting rows using pandas but the answers I've found so far havenot benefitted me. The question is how can i delete excess rows using python pandas (the limit of which we may not know, it can go up to 200000), but the cut-off index is 5000 rows. If you know another python way other than pandas, do answer as well. 	' '. See also pep 342 - coroutines via enhanced generatorspep written by guido van rossum and phillip j. eby ; implemented by phillip j. eby. includes examples of some fancier uses of generators as coroutines.	\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_excel('C:\\Users\\user\\Desktop\\test.xlsx')\n\ndf.columns = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16', 'col17', 'col18', 'col19', 'col20', '	1
Running a tester file in the VSC terminal - ModuleNotFoundError. I have made a tester file to check my other files are implementing correctly, however I can only get an output by clicking run on the file  (top right green arrow). When I type 'python Test.py' in the terminal I get :  Fatal Python error: initsite: Failed to import the site module ModuleNotFoundError: No module named 'site' Current thread 0x0000000102c0ce00 (most recent call first):  I assume this is an environment issue for my terminal? I am in the correct folder (one above Test.py). Any ideas how I can change this? Thanks! 	\n  I assume this is an environment issue for my terminal?	if you create a python directory, you can use the''===' '===' linux'if you don't need to support older python versions. bpo - 13847, bpo - 14180 : time and datetime : overflowerror is now raised instead of valueerror if a timestamp is out of range. oserror is now raised if c functions gmtime ( ) or localtime ( ) failed	1
Raspberry PI - Python Network NAME. I've made a small info / kiosk system where a user can scan a QR code on the screen to connect with the raspberry pi. On the screen (next to the QR code) I want to put the name of the network (because you have to be on the same network to have the interaction). How can I print the name of the network (wifi or cable) on the screen, the IP address is not the issue, neither the hostname. I am just struggling with the name of the network where the Pi is connected too.. Thanks 	' '. ip _ address ( ) factory function, which automatically determines whether to create an ipv4 or ipv6 address based on the passed in value: &gt;&gt;&gt; ipaddress. ip _ address ('192. 0. 2. 1') &gt;&gt;&gt; ipaddress. ip _ address ('192. 0. 2. 1') &gt;&gt;&gt; ipad	ipaddress is a module for inspecting and manipulating ip addresses, the first thing you'll see is a list of ip addresses. This list is a list of ip addresses, and the first thing you'll see is a list of ip addresses. The first thing you'll see is a list of ip addresses. The first thing you'll see is a list of ip addresses. The first thing you'll see is a list of ip addresses.	1
"""parse tab-delimited CSV file 'text.txt' into a list"""	\n\nimport csv\nimport sys\nimport os\nimport re\nimport cStringIO\nimport io\nimport json\nimport itertools\nimport string\nimport itertools as it\nimport operator\nimport collections\nimport itertools as it\nimport operator.itemgetter\nimport operator.nested as op\nimport operator.nested.function as op\nimport operator.nested.function as opn\nimport operator.nested.function as opn\nimport operator.nested.function as opn\nimport operator.nested.function as opn\nimport operator.nested	\n\nimport csv\nimport sys\n\n	1
"""print a list `l` and move first 3 elements to the end of the list"""	\nprint(l[3:])\nl[3:] = l[:3]\n	\n     print(l)\n     l.extend(l[:3])\n     print(l)	1
"""Python split a string using regex"""	\nre.split('\\W+', 'This is a string with words')\n\n	\n\nimport re\n\nfrom collections import defaultdict\n\nfrom. import _base\nfrom. import _base_types\nfrom. import _base_string_types\nfrom. import _base_string_util\nfrom. import _base_string_util_base\nfrom. import _base_string_util_base_types\nfrom. import _base_string_util_base_types\nfrom. import _base_string_util_base_types_base\nfrom. import _base_string_util_base_types_base\nfrom. import _base_string_util	0
Is there any function in which .wav file will generate. I am stuck on the .wav file extension, I used gtts method to convert text into the speech and save the file and it is working perfectly but the problem is gtts only support the .mp3 extension but I need the output file with .wav extension. So I am question is, if any function like gtts to convert text into speech and save the file with .wav extension? or anyone who already done work on this module. Please share your opinion. Thanks 	' '##s = audioop. findmax ( outputdata, 800 ) # one tenth second out _ test = outputdata [ pos * 2 : ] in _ test = inputdata [ pos * 2 : ] ipos, factor = audioop. findfit ( in _ test, out _ test ) # optional ( for better cancellation ) : # factor = audioop. findfactor ( in _ test [ ipos * 2 : ipos * 2 + len (	' 'tell ( ) and wave _ read. setpos ( ) methods. wave _ write. writeframesraw ( data )  write audio frames, without correcting nframes. changed in version 3. 4 : any bytes - like object is now accepted. it will raise an error if the output stream is not seekable and the total number of frames that have been written.	1
Is there a torchsummary equivalent in Tensorflow?. I am using GPU to run some very large deep learning models on a dataset of size 55GB. If I use a batch size greater than 1, I get a resource exhausted error. Even with a batch size of 1, I get segmentation faults. GPU memory is 10GB and Server has 32GB of RAM. Is there a way that I could know how large the data (batch size of 1) will occupy in the GPU? I am using tf.Keras to fit models. Is there a torchsummary equivalent in TensorFlow? 	python's api has many different types of APIs.''- sized arenas, but never freed arenas. with this patch, python will free arenas when they ’ re empty. The net effect is that on some platforms, when you allocate many objects, python ’ s memory usage may actually drop when you delete them and the memory may be returned to the operating system. ( implemented by evan jones, and reworked by tim peters. ) Note that	' 'implemented by (in alphabetical order ) brett cannon, nick coghlan, grant edwards, john ehresman, kurt kaiser, neal norwitz, tim peters, armin rigo, and neil schemenauer, plus the participants in a number of ast sprints at conferences such as pycon. evan jones''s patch to obmalloc, first described in a talk at	1
i want to compile .py to .exe. i want to compile .py to .exe. But when i do so the exe files is too big. Is there a solution?? i want the exe to be a smaller i know that  python was not meant to be compiled, executables made from python are bound to be large , but the problem is i have learnt python like 3 years, and now i want to make apps/games for windows. i can't just install python on every device?? i want to make it small i learnt that there is something called executable-packing?? using tools like crinkler how can we do that with python with pyinstaller or cx_freeze 	ccompiler is a built-in class that can be used for all the compile / link steps in building a single project.	ccompiler is a built-in module for distutils. You can use it as a ccompiler instance to create a single project. import distutils ccompiler = distutils.ccompiler(ccompiler) ccompiler = ccompiler(ccompiler) ccompiler = ccompiler(ccompiler)	1
live updates of google trends api python. Hi I played with pytrends for few hours and wonder if there is a way to get live updates and not only historical value of specific keyword? I want to train model that use the google trends but what can I do if I don't have live data. Any websocket or something similar will be appreciated 	' '5 > > > p. y = 0. 5 > > > print ( _ _ ('message with coordinates : (  point. x :. 2f,  point. y :. 2f  ) ',... point = p ) message with coordinates : ( 0. 50, 0. 50 ) > > > > from wherever import dollarmessage as _ _ > > print ( _ _ ('message with $ num $ what ',	The os. stat _ float _ times ( ) function is deprecated. abc. abstractproperty has been deprecated, use property with abc. abstractmethod ( ) instead. abc. abstractclassmethod has been deprecated, use classmethod with abc. abstractmethod ( ) instead. abc. abstractstaticmethod has been deprecated, use staticmetamethod with abc. abstractmethod ( ) instead. abc. abstractstaticmethod has been deprecated, use staticmetamethod with ab	1
"""open a 'gnome' terminal from python script and run  'sudo apt-get update' command."""	\nos.system('gnome')\nos.system('sudo apt-get update')\n\n	\n\nimport os\nimport subprocess\nimport sys\nimport time\n\n	0
Matplotlib plot function output differs from seaborn's lineplot. I want to plot a PDF function given data which follows a normal distribution. Mainly I followed this link. Now, if I am working on the data created like on that website (x=np.linspace()) and I plot it with either seaborn.lineplot() or matplotlib.pyplot.plot(), I get a normal curve as shown on the website linked above. But when I do this with my own data (which I believe is normal, but with a lot more data points) instead of initializing it with np.linspace I get a clear normal curve with seaborn's lineplot and a messy normal curve with matplotlib's plot function. I have tried to look for default arguments on both functions but couldn't find any (except estimator) which would cause this behavior. The estimator argument of Seaborn's lineplot was the only argument that looked like it could do something like this but setting it to None did not make any difference (and it kind of makes sense I think since the y value is always same for a specific x so averaging out will produce the same value). I used to think both functions are the same, but then why do they have different output? 	The _ _ wrapped _ _ attributes of the _ _ function are not inherited by the _ _ wrapped _ _ attributes. The _ _ wrapped _ _ attributes of the _ _ function are not inherited by the _ _ wrapped _ _ attributes of the _ _ wrapped _ _ functions. The _ _ wrapped _ _ attributes are not inherited by the _ _ wrapped _ _ attributes of the _ _ wrapped _ _	You can use tp _ init and tp _ _ init functions. Just name them _ _ new _ _ or _ _ init _ _ as appropriate.	1
discord.py get user "about me" section. I was wondering if it was possible using discord.py to get the about me section of a given user. I did not find anything in the API documentation so I'm asking here to be sure. 	' 'the name of the parameters to not be available to the user. This is useful when parameter names have no real meaning, if you want to enforce the order of the arguments when the function is called or if you need to take some positional parameters and arbitrary keywords. use keyword - only when names have meaning and the function definition is more understandable by being explicit with names or you want to prevent users relying on the position of the argument being passed.	You can combine multiple literals in a single literal. You can use''more literals : def http _ error ( status ) : match status : case 400 : return " bad request " case 404 : return " not found " case 418 : return " i'm a teapot " case _ : return " something's wrong with the internet " note the last block : the “ variable name ” _ acts as a wildcard and never fails to match. if no case matches, none of the branches is	1
Get embed footer from reaction message. I want the person who used the command to be able to delete the result. I have put the user's ID in the footer of the embed, and my question is: how do I get that data from the message where the user reacted to. reaction.message.embed.footer doesn't work. I currently don't have code as I was trying to get that ID first. Thanks in advance! 	Asyncio. basetransport. get _ extra _ info ( ) now returns a safe to use socket object when ‘ socket ’ is passed to the name parameter. ( contributed by yury selivanov in bpo - 37027. ) the function asyncio. basetransport. get _ extra _ info ( ) now returns a safe to use socket object when ‘ socket ’ is passed to the name parameter. ( contributed by yury selivanov in bpo -	' '( ), visit _ bytes ( ), visit _ nameconstant ( ) and visit _ ellipsis ( ) are depreated now and will not be called in future python versions. add the visit _ constant ( ) method to handle all constant nodes. ( contributed by serhiy storchaka in bpo - 36917. ) the asyncio. coroutine ( ) decorator is depreated and will be removed in version 3.	1
Auto run python scripts on pycharm while opening. I want to auto run the python script when I open it from the terminal so that I won't have to press the run button From the terminal I want to open the file as : pycharm-community main.py How do I auto run it while it opens? 	python gui toolkit is available from https://docs.python.org/2/library/gui.html#gui-programming-on-the-mac	ide is running. if you want to run python scripts from the terminal window or from the finder you first need an editor to create your script. macos comes with a number of standard unix command line editors, vim and emacs among them. if you want a more mac - like editor, bbedit or textwrangler from bare bones software ( see http : / / www. barebones. com / products / bbedit / index. html. html.	1
Merge two dataframes based on date column and Id column. I have two data frames df and df1, I want to merge based on the date also based on Id column, df looks like     arrival input_fid     01-01-2021 719   02-01-2021 719   02-01-2021 599   02-01-2021 599   02-01-2021 479   01-01-2021 359   04-01-2021 359     df1 looks like     date input_fid prcp     02-01-2021 479 0.44   01-01-2021 359 0.14   02-01-2021 599 0.33   03-01-2021 599 0.24   02-01-2021 719 0.08   01-01-2021 719 0.02   04-01-2021 359 0.10     The expected result is,     arrival input_fid prcp     01-01-2021 719 0.02   02-01-2021 719 0.08   02-01-2021 599 0.33   04-01-2021 359 0.10   02-01-2021 479 0.10   01-01-2021 359 0.14   04-01-2021 359 0.10     I am not sure how to get that using two different columns. 	' 'itermonthdays2 ( year, month )  return an iterator for the month month in the year year similar to itermonthdates ( ), but not restricted by the datetime. date range. days returned will be tuples consisting of a day of the month number and a week day number.''itermonthdays3 ( year, month )  return an iterator for the month month in the year year similar to itermonthdates ( ), but not restricted by the datetime. date	' '##time.date (2003, 12, 2 ) > > > age = now. strftime ( " % m - % d - % y. % d % b % y is a % a on the % d day of % b. " )'12 - 02 - 03. 02 dec 2003 is a tuesday on the 02 day of december')	1
Django button in admin. On user form view, add button Login As, that button will execute functionality that we login as that user. Only admins can see/execute this functionality. This is my question, how this to make? 	django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.django.djan	' '##dget creates a box of buttons, such as is commonly used for ok cancel. class tkinter. tix. combobox  the combobox widget is similar to the combo box control in ms windows. the user can select a choice by either typing in the entry subwidget or selecting from the listbox subwidget.	1
What does the python runtime environment mean?. I was reading this article about the sys module in python And I came across this line:  The sys module in Python provides various functions and variables that are used to manipulate different parts of the Python runtime environment. It allows operating on the interpreter as it provides access to the variables and functions that interact strongly with the interpreter.  Can someone explain what this means? I don't get it 	''the type of the trace function registered using pyeval _ setprofile ( ) and pyeval _ settrace ( ). the first parameter is the object passed to the registration function as obj, frame is the frame object to which the event pertains, what is one of the constants pytrace _ call, pytrace _ exception, pytrace _ line, pytrace _ return, pytrace _ c _ call, py	''executes expressions in annotations at their definition time, the compiler stores the annotation in a string form equivalent to the ast of the expression in question. if needed, annotations can be resolved at runtime using typing. get _ type _ hints ( ). in the common case where this is not required, the annotations are cheaper to store ( since short strings are interned by the interpreter ) and make startup time faster.	1
How to speed up large test-suite run duration using pytest?. I have a pytest test-suite which contains over 30,000 test cases. When I run it, it takes over 10 hours to run. However, when I cut the number of test cases down to 1,000, it completes in 39 seconds! Any idea on what is going on here? The test cases are very simple, just calling one function which is doing no I/O (no network calls, DB calls etc). Any help would be great! Best, Dave. 	' 'when counts argument is not none. bpo - 42934 : use tracebackexception ’ s new compact param in testresult to reduce time and memory consumed by traceback formatting. bpo - 38250 : add randbytes ( ) to random. _ _ all _ _. bpo - 38250 : [ enum ] flags consisting of a single bit are now considered canonical, and will be the only flags returned from listing and iterating	' '##ple ( test, formatted _ err ) to the instance ’ s failures attribute, where formatted _ err is a formatted traceback derived from err. addskip ( test, reason )  called when the test case test is skipped. reason is the reason the test gave for skipping. the default implementation appends a tuple ( test, reason ) to the instance ’ s failures attribute, where formatted _ err is a formatted traceback	1
"""Sum integers contained in strings in list `['', '3.4', '', '', '1.0']`"""	\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\n\nif sys.version_info[0] >= 3:\n    long = int\n    long_long = long\n    long_long_ = long_long\n    long_long_long = long_long_long\n    long_long_long_ = long_long_long_\n    long_long_long_long = long_long_long_long\n    long_long_long_long_ = long_	\n     return sum([int(i) for i in strings])	1
How to pass data in body of a get request in python?. So i have a hash that i want to pass in the body of get request i am currently using requests library from python, i am doing something like this in my code. I am using falcon framework. requests.get(url, headers=head, data=json.dumps({user_id: 436186})) is it the right approach to pass the data in body of get request? Because i am not able to hit the api and getting 400 from the other side i suspect it's because of data not being able to pass in the get request. Or is there some other library which has the support? 	This password manager extends httppasswordmgrwithdefaultrealm to support tracking uris for which authentication credentials should always be sent. httppasswordmgrwithpriorauth. add _ password ( realm, uri, user, passwd, is _authenticated = false )  realm, uri, user, passwd are as for httppasswordmgr. add _ password ( ). is _authenticated sets the initial value of the is _authenticated = false )	' 'iterable object and can be used in a with statement. changed in version 3. 5 : the io. bufferediobase interface is now implemented and all of its reader operations are supported. httpresponse. read ( [ amt ] )  reads and returns the response body, or up to the next amt bytes. httpresponse. readinto ( b )  reads up to the next len ( b ) bytes of the response body into the buffer b.	1
How to use decision trees for survival analysis?. I have a problem understanding und applying Decision Trees for Survival Analysis in Python. I have a dataset, with the variables age, weight, size of tumor, volume, ... (all floats) and I want to know if there is a correlation with the overall survival(also a float). But how can I apply Decision Trees for that? In the literature, I only saw examples where y_train must be a categorical variable (such as 0 or 1, benign or malignant, ...) but it does not work on continuous variables like floats. However I want to create a decision tree, so that in the end you can find out that with a tumor size of  xx and a volume of yy your predictes overall survival is about  zzz. Can someone help me out with my problem? Does anyone has an idea where to read more about this topic? 	\nI have a dataset, with the variables age, weight, size of tumor, volume,... (all floats) and I want to know if there is a correlation with the overall survival(also a float). But how can I apply Decision Trees for that? In the literature, I only saw examples where y_train must be a categorical variable (such as 0 or 1, benign or malignant,...) but it does not work on continuous variables like floats. However I want to create a decision tree, so that in the end you can find out that with a tumor size of  xx and a volume of yy	''statistics. mode ( data ) return the single most common data point from discrete or nominal data. the mode ( when it exists ) is the most typical value and serves as a measure of central location. if there are multiple modes with the same frequency, returns the first one encountered in the data. if the smallest or largest of those is desired instead, use min ( multimode ( data ) ) or max ( multimode ( data ) ) ). if the input data is empty, statistics. mode ( data ) returns the single most common	1
Extract multiple frames from camera using ROS. How do I extract multiple frames from a video streaming using ROS ? I subscribed to my camera topic : self.image_sub = rospy.Subscriber('/bebop2/image_raw',Image, self.image_callback) And then : frame = self.bridge.imgmsg_to_cv2(msg,desired_encoding='bgr8') This way I have the actual frame from my streaming. How can I store N frames (the actual and previous ones) ? 	\n  How can I store N frames (the actual and previous ones)?	\nI have a function that extracts the frames from the camera. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the frames in a list. I have a function that stores the	1
How to make the python program work in the background. how can i make my program run silently when running? I would like it to leave no trace and nothing to appear visually, in C# we say '' Silent Load '', but I don't know how it works in Python obs : i use pycharm for coding 	' '( 0l ) ; pyobject _ print ( item, stdout, 0 ) ; pyobject _ decref ( item ) ;... The second case of problems with a borrowed reference is a variant involving threads. normally, multiple threads in the c debugger to figure out why his _ _ del _ _ ( ) methods would fail... The second case of problems with a borrowed reference is a variant involving threads.	stdscr. refresh ( ) stdscr. getkey ( ) wrapper ( main ) the wrapper ( ) function takes a callable object and does the initializations described above, also initializing colors if color support is present. wrapper ( ) then runs your provided callable. once the callable returns, wrapper ( ) will restore the original state of the terminal. the callable is called inside a try... except that catches exceptions, restores the original state of the terminal.	1
"""remove all non-alphanumeric characters except space from a string `text` and lower it"""	\nre.sub('[^a-zA-Z0-9 ]+', '', text)\n\n	\n     return re.sub(r'[^\w\s]', '', text).lower()	1
File dependend DAG execution. I build a DAG that begins with the download of a file over the SFTPOperator, I save it and proceed with accessing and processing it, with a PythonOperator. I had no issues with this approach at all, till I started to scale up my celery-workers from 1 to 2. Now I run in to the problem of a file that isn't available in both workers. How do I solve it? Do I download the file over the SFTPHook and combine these Tasks? Can I constrain the spread on to different workers? kind regards, CreedsCode 	The logging module's filehandler class and its subclasses watchedfilehandler, rotatingfilehandler, and timedrotatingfilehandler now have an optional delay parameter to their constructors. if delay is true, opening of the log file is opened.	\n  How do I solve it? Do I download the file over the SFTPHook and combine these Tasks?	1
In pygame how can i create a data struct that keeps track of resizing events and the coordinates of objects?. I'm looking to keep my mouse events in sync with my objects after resizing the screen. I'm told I need to create a data structure to keep track of:  Resizing events  New coordinates to match the resize   How can I accomplish this using simple algebraic equations and integrate it into a resize event for accurate updating? 	You can use ttk.windows to display a single window at a time: ttk.windows.windows.set(' ')	' '( ) ) virtual events  this widget generates a  '( ) virtual event after a new tab is selected. ttk. notebook  class tkinter. ttk. notebook  add ( child, * * kw )  adds a new tab to the notebook. if window is currently managed by the notebook but hidden, it is restored to its previous position. see tab options for the list of available options. forget ( tab _ id )  removes the tab	1
The dash_html_components package is deprecated. Please replace `import dash_html_components as html. I am trying to use dash 2.0, I also replaced import style in my all files but the problem is occurring in-dash bootstrap, Is there any method by which I can upgrade dash bootstrap for smoother use in dash 2.0 rather than manually changing.  /home/sarim/Desktop/biz-pulse-vm-20210727T040204Z-001/biz-pulse-vm/venv/lib/python3.8/site-packages/dash_bootstrap_components/_table.py:5:  UserWarning: The dash_html_components package is deprecated. Please replace import dash_html_components as html with from dash import html import dash_html_components as html  /home/sarim/Desktop/biz-pulse-vm-20210727T040204Z-001/biz-pulse-vm/venv/lib/python3.8/site-packages/dash_extensions/enrich.py:7:  UserWarning: The dash_core_components package is deprecated. Please replace import dash_core_components as dcc with from dash import dcc import dash_core_components as dcc 	The xmllib module was added in python 1. 5. 2 as part of the python documentation. The xmllib module was added in python 1. 5. 2 as part of the python documentation. The xmllib module was added in python 1. 5. 2 as part of the python documentation. The xmllib module was added in python 1. 5. 2 as part of the python documentation.	kw = 'name': " quixote ",'version': " 0. 5. 1 ",'description': " a highly pythonic web application framework ", #...  if ( hasattr ( core,'') hasattr ( core,'') hasattr ( core,'') hasattr ( core,'') hasattr ( core,'') hasattr ( core,'') hasat	1
How do you import and use Spark-Koalas in palantir-foundry. How can I -- in Palantir-foundry -- import and use the Koalas: pandas API for Apache Spark open source python package. I know that you can import packages that don't exist through Code Repo and have done this, can I do this same process for Koalas package or do I need to follow another route? 	' 'names in the 1st are not yet available, because the first module is busy importing the 2nd. in this case, if the second module is only used in one function, then the import can easily be moved into that function. by the time the import is called, the first module will have finished initializing, and the second module can do its import.	If you need to create a. pyc file for foo – that is, to create a. pyc file for a module that is not imported – you can do so by using python foo. py as a shell command.	1
lambda function of undertermined number of arguments. I am new to use python for programming. I want to create a function of list without determined number of arguments. My task is as follows: if I input s=5 and idx=[2,3] with numerical values [0.3, 0.7], it means that I have to create a list [t0, t1, 0.3, 0.7, t4]. The list can be treated as a function of three variables t0, t1, and t4. I guess I may need to use *args, but I do not how to do it in general. 	' '* 2 ) this gives you a list that contains 5 lambdas that calculate x * * 2. you might expect that, when called, they would return, respectively, 0, 1, 4, 9, and 16 however, when you actually try you will see that they all return 16: &gt;&gt;&gt; x * * 2 &gt;&gt;&gt; x * * 2 &gt;&gt;&gt; x * * 2 &gt;&gt;&gt	You can use the built-in'':'new - value ','b': 100 &gt;&gt;&gt;'':'new - value ','b': 100 &gt;&gt;&gt;'':'new - value ','b': 100 &gt;&gt;&gt;'':'new - value ','b': 100 &gt;&gt;	1
how to set correct batch_size and steps_per_epoch in keras?. I have 20000 RGB images. I set batch_Size = 1 (due to GPU capacity). So now does it mean the model weights are changing with one-by-one pictures or it depends on the steps_per_epoch? How should I set the steps_per_epoch and epochs for using all of 20000 images to be involved in training in different epochs? 	\n    batch_size = 1 (due to GPU capacity)	The threading module now lets you set the stack size used when new threads are created. The stack_size ( [ * size * ] ) function returns the currently configured stack size, and supplying the optional size parameter sets a new value. Not all platforms support changing the stack size, but windows, posix threading, and os / 2 all do.	1
Do I need a setup.cfg if I have a setup.py?. I use setuptools to build my python package. I was using just a setup.py file, but I added a pyproject.toml in accordance with this tutorial, which appears to have been recently updated to include that file. What I can't tell from that tutorial or this one, is whether I need to have a setup.cfg if I'm still using setup.py, and if so, what should be in it. It does show a file tree with both, but then implies that file structure is only indicative with (for people using primarily setup.cfg)  If you create a setup.py file, this will enable direct interaction with setup.py (which generally should be avoided), and editable installs. This file used to be required, but can be omitted in modern setuptools.  	''simple example : more metadata, and the specification of pure python modules by package, rather than by module. This is important since the distutils consist of a couple of dozen modules split into ( so far ) two packages ; an explicit list of every module would be tedious to generate and difficult to maintain.	' '' : ['data / *. dat'], ) changed in version 3. 1 : all the files that match package _ data will be added to the manifest file if no template is provided. see specifying the files to distribute.	1
Using python to create a ChatBot in GupShup Bot Builder. I'm trying to create a chatbot using gupshup, but I don't have much experience with JS, and for my implementation, it will be easier to code in python, but I'm not finding any material about it. Is it possible to develop a ChatBot with python using GupShup? Thanks 	\n\nYes, it is possible to develop a chatbot with python using GupShup.\n\nSteps to follow:\n\nDownload GupShup Bot Builder.\nInstall GupShup Bot Builder.\nDownload the python code from the GupShup website.\nCopy the downloaded python code to your project directory.\nRun the python code.\n\nSteps to follow:\n\nDownload GupShup Bot Builder.\nInstall GupShup Bot Builder.\nDownload the python code from the GupShup website.\nCopy the downloaded python code to your project directory.\nRun	''in simulated shells, such as those presented by idle and other development environments. This is described in pep 264. ( contributed by michael hudson.) The new license introduced with python 1. 6 wasn ’ t gpl - compatible. this is fixed by some minor textual changes to the 2. 2 license, so it ’ s now legal to embed python inside a gpled program again. Note that python itself is not gpled, but instead is	0
Django remove all default migration. Is there a way to remove all default django migration? My app doesn't use any of the default migration so I think it's a good idea to remove all unused migration 	' '##logrecordfactory ( record _ factory ) this pattern allows different libraries to chain factories together, and as long as they don ’ t overwrite each other ’ s attributes or unintentionally overwrite the attributes provided as standard, there should be no surprises. However, it should be borne in mind that each link in the chain adds run - time overhead to all logging operations, and the technique should only be used when the use of a filter does not provide the desired result.	\n  Is there a way to remove all default django migration?	1
Is it possible to write python code inside Flutter using Android Studio?. I'm working on Flutter project in Android Studio platform and I faced a problem with how to write and run python API code inside my Flutter project without letting it as a backend code in another platform? since when I run my Flutter project that connected with python API code in another platform as a backend using post method, it's worked with the emulator but it does not work with my physical android device. So is there any recommend solution for either the first problem or the second. Thanks. 	bpo - 30389 : adds detection of visual studio 2017 to distutils on windows. bpo - 31358 : zlib is no longer available on windows.	' '##4 : the new os. posix _ spawn added in 3. 7. 0b1 was removed as we are still working on what the api should look like. expect this in 3. 8 instead. bpo - 33475 : fixed miscellaneous bugs in converting annotations to strings and optimized parentheses in the string representation. bpo - 28055 : fix unaligned accesses ( ). bpo - 28055 : fix unaligned accesses (	1
Heikin Ashi without a stock's entire history?. I'm trying to loop through hundreds of stock tickers, calculating the most recent Heikin-Ashi open and close value for each. However, you need the previous HA open and close to calculate the current HA open. Is there any way to do this without having to deal with a stock's entire history? 	\n  Is there any way to do this without having to deal with a stock's entire history?	' 'the window. when shown, this pane freezes the opening lines for block code, such as those beginning with class, def, or if keywords, that would have otherwise scrolled out of view. the size of the pane will be expanded and contracted as needed to show the all current levels of context, up to the maximum number of lines defined in the configure idle dialog ( which defaults to 15 ). if there are no current context lines and the feature is disabled, it will freeze the opening lines for block code, such as those beginning with class, def, or	1
How can I classify a dataset after one-hot encoding the target class?. I want to Classify a dataset with kernel machine. The Target-Class has 5 different values and I want to one-hot encoding it. After that I have 5 Target-Columns. I do the Training 5 times, one time per Target-Column. Now I want to classify a new sample. I classify the Sample 5 times using the 5 Trainig-model I got. At the end I look which Prediction has the maximum value over the 5 predictions and then I classify the sample according to the Class with the maximum prediction. I am not sure that I am doing the right thing. How can I do that in the right way? 	' '( self ) :... return list ( self. keylist )...	You can use es as a base class: es.embody both the data ( attributes ) and code ( methods ) specific to a datatype. es.embody both the data ( attributes ) and code ( methods ) specific to a datatype. a class can be based on one or more other classes, called its base class ( es ). it then inherits the attributes and methods of its base classes. This allows an object model to be successively refined by inheritance. You might have a generic mailbox that provides basic access	1
"""Get the integer location of a key `bob` in a pandas data frame"""	\n\nimport pandas as pd\nimport numpy as np\n\n	\n     return data.index.get_loc(bob)	1
"""append elements of a set `b` to a list `a`"""	\n\nfrom itertools import product\nfrom operator import itemgetter\n\nfrom numpy.lib.stride_tricks import as_strided\nfrom numpy.lib.stride_tricks import as_strided_mask\nfrom numpy.lib.stride_tricks import as_masked_strided\nfrom numpy.lib.stride_tricks import as_masked_mask\nfrom numpy.lib.stride_tricks import as_masked_masked_strided\nfrom numpy.lib.stride_tricks import as	\n[i for i in b]\n	1
How to get word embeddings back from Keras?. Say you create your own custom word embeddings in the process of some arbitrary task, say text classification. How do you get a dictionary like structure of {word: vector} back from Keras? embeddings_layer.get_weights() gives you the raw embeddings...but it's unclear which word corresponds to what vector element. 	''for a pattern. findall ( ) returns a list of matching strings : &gt;&gt;&gt; import re &gt;&gt;&gt; s = '12 drummers drumming, 11 pipers piping, 10 lords a - leaping' &gt;&gt;&gt; s.findall ('12 drummers drumming, 11 pipers piping, 10 lords a - leaping'	\nYou can use the embeddings_layer.get_weights() method to get the weights of the embeddings layer. You can then use the weights to create your own custom word embeddings.\n\nA:\n\nYou can use the embeddings_layer.get_weights() method to get the weights of the embeddings layer. You can then use the weights to create your own custom word embeddings.\n\n	1
Why don't Python packages come with documentation, like R?. When you download a package to R, they always come with the documentation, which is very handy and lets you use the Help panel from RStudio offline. Why is not the same with python packages? Is it not possible to do the same from the Spyder Help panel? You need to be online to access the documentation. 	' '##c object structures slot type typedefs examples supporting cyclic garbage collection controlling the garbage collector state api and abi versioning distributing python modules key terms open source licensing and collaboration installing the tools reading the python packaging user guide how do i...?... choose a name for my project?... create and distribute binary extensions?... install pip in versions of python prior to python 3. 4?... install packages just for the current user?...	' '##group, comp. lang. python, and a mailing list, python - list. the newsgroup and mailing list are gatewayd into each other – if you can read news it ’ s unnecessary to subscribe to the mailing list.''##group, comp. lang. python, and a mailing list, python - list. the newsgroup and mailing list are gatewayd into each other – if you can read news it ’ s unnecessary to subscribe to the	1
How to fill/blur the inside of bounding box in YOLO object detection?. I have used YOLOv4 to detect objects in an image now I want to blur those objects or superimpose black color inside the bounding box. How can I do that using OpenCV or some other library? 	' ') fill the shape drawn after the last call to begin _ fill ( ). whether or not overlap regions for self - intersecting polygons or multiple shapes are filled depends on the operating system graphics, type of overlap, and number of overlaps. for example, the turtle star above may be either all yellow or have some white regions.	\nYou can use the following code to blur the bounding box:\n\nimport cv2\nimport numpy as np\n\nimg = cv2.imread('image.jpg')\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nbbox = cv2.boundingRect(gray)\n\nbbox = cv2.minArea(bbox)\n\nbbox = cv2.cvtColor(bbox, cv2.COLOR_BGR2GRAY)\n\nb	1
Why does Google Cloud Compute Engine IP differ from the static one I have reserved?. I have set a static IP address for my Google Cloud Compute Engine. When I go to the network details of the engine, it tells it is 34.88.xx.xx However - when I now run a test python script in the cloud shell, it tells me that the requests comes from an IP that is 34.91.xx.xx It looks like I should not run the script on the Shell but somehow run it in the compute engine. Hard to figure out how that could be done. 	' '##auth objects abstractbasicauthhandler objects proxybasicauthhandler objects httpbasicauthhandler objects proxydigestauthhandler objects httphandler objects httpshandler objects filehandler objects ftphandler objects cacheftphandler objects unknownhandler objects httperrorprocessor objects examples legacy interface urllib. request restrictions urllib. response restrictions urllib. response restrictions urllib. response restrictions urllib. response restrictions urllib. response restrictions urllib. response restrictions urllib. response restrictions urllib.	\nThe IP address of the Compute Engine is not the same as the IP address that you have reserved.\n\nA:\n\nThe IP address of the Compute Engine is not the same as the IP address that you have reserved.\n\nThe IP address of the Compute Engine is 34.88.xx.xx.\n\nThe IP address of the Compute Engine is 34.88.xx.xx.\n\nThe IP address of the Compute Engine is 34.88.xx.xx.\n\nThe IP address of the Compute Engine is 34.88.xx.xx.\n\nThe	1
"""set pythonpath in python script."""	\nsys.path.insert(0, '.')\n\n	\nimport os\nimport sys\nimport inspect\nimport importlib\nimport importlib.util\nimport importlib.machinery\nimport importlib.util\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.util\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\nimport importlib.machinery\n	0
How to close chrome manually and do .quit() automatically. My script is in python with selenium is to login automatically on some site and after(i use chrome like any browser), I want when I finish to use chrome (when I close it), automatically close the chromedriver.exe else the chromedriver.exe is all time running. 	' '. if block raises an exception, the _ _ exit _ _ ( type, value, traceback ) is called with the exception details, the same values returned by sys. exc _ info ( ). the method''. if block raises an exception, the _ _ exit _ _ ( type, value, traceback ) is called with the exception details, the same values returned by sys. exc _ info ( ). the method ’ s return value controls whether the exception is	qtwidgets.addhandler is a built-in addhandler that will terminate the qthread when we exit app. abouttoquit. connect ( self. force__ quit ) # lay out all the widgets layout = qtwidgets.qvboxlayout ( self ) layout. addwidget ( self. work _ button ) layout. addwidget ( self. clear _ button ) layout. addwidget ( self. clear _ button ) layout. addwidget ( self. clear _ button )	1
How do built in macros on Emulators work?. I'm building a script to automate some stuff on my Android emulator I'm currently using pyautogui to do it tho it would be nice if there was some sort of way I can directly interact with the emulator without it relying on my mouse I know there's an option using ADB but that requires the android to be rooted a lot of android emulators like Nox, Bluestacks, LDplayer have built-in macros that don't require the device to be rooted. How do these emulators send commands to the emulator is that something I can tap into and send commands through that instead? 	You can use c + + to extend python with c. c + + ''1. extending python with c or c + +  it is quite easy to add new built - in modules to python, if you know how to program in c. such extension modules can do two things that can ’ t be done directly in python : they can implement new built - in object types, and they can call c library functions and system calls.''	_ macros is a list of tuples to define explicitly a list of tuples to undef _ macros a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly a list of tuples to undef explicitly	1
Can not install cleverhans version 3.1.0. I am trying to install cleverhans verion 3.1.0 but getting following error pip install cleverhans==3.1.0 Note: you may need to restart the kernel to use updated packages. ERROR: Could not find a version that satisfies the requirement cleverhans==3.1.0 (from versions: 2.1.0, 3.0.0, 3.0.0.post0, 3.0.1) ERROR: No matching distribution found for cleverhans==3.1.0 I want to access random_lp_vector method in 3.1.0 version which I am unable to access if I try in 3.0.1 also Is there any option available for adversarial training in the latest version which is 4.0.0 Please kindly help 	The - - user option to python - m pip install will install a package just for the current user, rather than for all users of the system.''the - - user option to python - m pip install will install a package just for the current user, rather than for all users of the system.''the - - user option to python - m pip install will install a package just for the current user, rather than for all users of the system.	python2 - m pip install somepackage # default python 2 python2. 7 - m pip install somepackage # specifically python 2. 7 python3 - m pip install somepackage # default python 3 python3. 4 - m pip install somepackage # default python 3 python3. 4 - m pip install somepackage # default python 3 py	1
How do I get rid of the '$' in the destination folder so I can download Anaconda?. Im trying to download Anaconda on Windows 10 but there is an error in the destination folder due to a '$' . I changed the username on my PC but it still doesn't change on the destination folder. How can I change the '$'? 	You can do this using the built-in installer module.\n\nimport installer\n\n# install without downloading\n\n\ninstallation.py:\n\ninstall installer.py\n\nwith open('your_installer.py', 'w') as f:\n    for i in range(10, 10):\n  ...\n\n	You can use the controlset \ control \ filesystem. this allows the open ( ) function, the os module and most other path functionality to accept and return paths longer than 260 characters. after changing the above option, no further configuration is required. changed in version 3. 6 : support for long paths was enabled in python. 4. 1. 3. installing without ui\nall of the options available in the installer ui can also be specified from the command line, allowing scripted installers to replicate.\n	1
"""view web page content that is generated using angular JS"""	\n\nimport os\nimport json\nimport logging\nimport requests\nimport time\nimport re\nimport urllib\nfrom datetime import datetime\nfrom flask import Flask, request, render_template, redirect, url_for, session, jsonify\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_migrate import Migrate\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom flask_wtf	\nself.response.write(self.angular.toJson(self.data))\nself.response.end()\n\nA:\n	1
"""get a random 4 digit number in python, from 0000-9999"""	\nrandom.randint(0, 99999)\n	\nrandom.randint(0, 9999)\n\n	1
How to run and test a django cloned project from github in visual studio code?. I have cloned a random project and trying to run it in my local system. I am using visual studio code editor. After opening the extracted folder in editor, I have clicked on run. At this point in time, a new chrome browser is getting opened and its showing that the server is down. I tried setting up a virtual environment and by using the command - python manage.py runserver . Even though I am unable to test that project. Could I get some insights to get rid of this issue as early as possible please? 	' '##o - 15308 : add ‘ interrupt execution ’ (  c ) to shell menu. patch by roger serwy, updated by bayard randel. bpo - 27922 : stop idle tests from ‘ flashing ’ gui widgets on the screen. add version to title of idle help window.	You can use the built-in bpo module from the standard library.\n\nimport bpo\n\n#!/usr/bin/env python\nimport urllib\nimport sys\nimport test\n\nclass Test(object):\n    def __init__(self, *args, **kwargs):\n\n   # ...\n\n  def test_test_test(self):\n\n\n  test_tests_test.__init__() will return a new test object.\n\n\nSo, you can do this:\n\ntest_tests = Test()\n\nwith open('test_	1
"""put '..' in the paths that we put in the os.listdir parameter"""	\n         if not self.path:\n             return\n         if self.path[-1] == '..':\n             self.path.pop()\n             self.path.pop()\n             self.path.append('')\n\n     def _get_dirs(self):\n         """get the directories in the path"""\n         if not self.path:\n             return\n         dirs = []\n         for i in range(len(self.path) - 1, -1, -1):\n             dirs.append(self.path[i])\n         return d	\nos.path.join('..', '..')\n\n	1
"""use relative path in Python"""	\n\nimport os\nimport sys\nimport shutil\nimport tempfile\nimport unittest\n\nfrom test import test_support\n\nimport modulefinder\n\n	\nos.path.join(os.path.dirname(__file__), '..', '..', '..')\n\n	1
"""extract string from python list"""	\n\nimport re\nimport sys\nimport os\nimport json\nimport argparse\nimport logging\nimport subprocess\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom itertools import chain\nfrom multiprocessing import Pool\nfrom functools import partial\nfrom pprint import pprint\n\nimport utils\nfrom utils import *\n\nlogger = logging.getLogger(__name__)\n\ndef get_args():\n     parser = argparse.ArgumentParser()\n     parser	\nlist(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split('.'), list(map(lambda x: x.split	1
"""move values from pandas columns with dicts into new columns containing just the value"""	\ndf.apply(lambda x: {k: v for k, v in x.items() if isinstance(v, dict)}, axis=1)\ndf.apply(lambda x: {k: v for k, v in x.items() if isinstance(v, dict)}, axis=1)\ndf.apply(lambda x: {k: v for k, v in x.items() if isinstance(v, dict)}, axis=1)\ndf.apply(lambda x: {k: v for k, v in x.items() if isinstance(v	\n     df = df.copy()\n     df = df.drop(columns=['index'])\n     df = df.rename(columns={col: f'{col}_value' for col in df.columns})\n     df = df.reset_index(drop=True)\n     return df	1
"""regex, find "n"s only in the middle of string `s`"""	\n     return re.sub(r"(?<=\w)(\w)(?=\w)", "", s)	\nre.findall('(?<=n)(?=n)', s)\n\n	1
Disection of re 're.compile(r"^[a-zA-Z][\w_]{2,23}[^_]$")'. I'm new to python programming and doing some challenges to improve my coding; I encounter the following regular expression: (r^[a-zA-Z][\w_]{2,23}[^_]$). Doing some research, I understand this: r = The expression is a raw string (not sure what this mean entirely) ^[a-zA-Z] = This tells me that the string must start with a letter [\w_]{2,23} = the body of the string from val[2] to val[23] must be alphanumeric [^_]$ = the end must be an underscore If my research is correct, I don't understand why the [\w_] contains an underscore on it. I thought for alphanumerics must be only [\w]. If I'm wrong, help me to clarify it. 	''is neither in a character class or preceded by an unescaped backslash.''s neither in a character class or preceded by an unescaped backslash. for example, here's a re that uses re. verbose ; see how much easier it is to read? charref = re.compile ( r " " " & [ # ] # start of a numeric entity reference ( 0 [ 0 - 7 ] + # octal form | [	' 'has been used to break up the re into smaller pieces, but it's still more difficult to understand than the version using re. verbose. More metacharacters  so far we ’ ve only covered a part of the features of regular expressions. in this section, we ’ ll cover some new metacharacters, and how to use groups to retrieve portions of the text that was matched.''has been used to break up the re into smaller pieces, but it ’ s still more difficult to understand than the	1
"""check the pattern of a column in a dataframe"""	\ndf.columns[df.columns.str.contains('^(\\d+)$')]\n\n	\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport os\nimport sys\nimport argparse\n\n	1
"""remove all non-alphanumeric characters except space from a string `text` and lower it"""	\n     return re.sub(r'[^\w\s]', '', text).lower()	\n\nimport re\n\nfrom pygments.lexer import Lexer, bygroups, byname, byattributes, byattributes_list, \\n    byattributes_list_item, byattributes_list_item_list, byattributes_list_item_list_item\nfrom pygments.token import Text, Comment, Keyword, Name, Punctuation, Operator, \\n    String, Literal, Generic, Whitespace, Punctuation, NameGroup, NameGroup_List, \\n    NameGroup_List_Item, Name	1
"""Print new line character as `\n` in a string `foo\nbar`"""	\n\nimport re\n\nfrom. import utils\nfrom. import utils.string_utils\nfrom. import utils.string_utils.escape\nfrom. import utils.string_utils.escape_regex\nfrom. import utils.string_utils.escape_regex_re\nfrom. import utils.string_utils.escape_regex_re_re\nfrom. import utils.string_utils.escape_regex_re_re_re	\nprint('foo\nbar')\n	1
"""Remove duplicate words from a string `text` using regex"""	\n     return re.sub(r'(\w)\1+', r'\1', text)	\n\nimport re\n\nfrom collections import defaultdict\n\nfrom. import utils\nfrom. import utils.string_utils\nfrom. import utils.string_utils.regex_utils\nfrom. import utils.string_utils.regex_utils.regex_utils	0
"""open a browser tab after GET and POST requests in python"""	\n\nimport os\nimport sys\nimport urllib.request\nimport webbrowser\n\n	\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nurllib.request.urlopen('http://www.google.com')\nur	1
How to disable SQLAlchemy lazy loads on detached instance relationships?. I've developed a JDO-like Fetch Group feature in Python with SQLAlchemy to control the pruning of object graphs for marshalling web service responses. During this process I detach the instances using session.expunge(entity) The issue is that when the JSON marshaller or pydantic accesses an instance attribute relationship which was not loaded yet, even though the instance is detached, the SQLAlchemy lazy loading still kicks in for that attribute and fails because the instance is not bound to a session anymore (obviously): DetachedInstanceError(Parent instance MyClass at 0x1439051f0 is not bound to a Session; lazy load operation of attribute 'relation' cannot proceed) So, my first question, is why are the lazy loaders not disabled when an instance is detached as it doesn't make sense to me. Secondly, if that is a feature, how can I disable or work-around lazy loaders to prevent this error and let the  attribute relationship in question appear None to the marshaller? I have found that setting self.__dict__['relation'] = None helps in some circumstance in fooling the lazy loaders in not kicking in but it does not always work unfortunately... 	In the examples below, “ the attribute ” refers to the attribute whose name is the key of the property in the owner class ’ _ _ dictionary. The attribute is the key of the property in the owner class. The attribute is the key of the property in the owner class. The attribute is the key of the property in the owner class. The attribute is the key of the property in the owner class. The attribute is the key of the property in the owner class. The attribute is the key of the property in the owner class. The attribute is the	The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or none depending on the first argument. The 4th argument is a list of values, which is a list of values. The first argument is a list of values. The second argument is a list of values. The third argument is a list of values. The fourth argument is a list of values. The fourth argument is a list of values. The fourth argument is a list of values. The first argument is a list of values. The first argument is	1
How can I get Custom Payload as string. I have a Dialogflow CX agent that returns a Custom payload. My client is a Python application using the dialogflowcx_v3beta1 SDK to call DetectIntent. The application needs to forward the custom payload in JSON format to another application, but I have been unable to find a way to convert the structured payload to JSON. There is no schema associated with the custom payload, which could be literally any valid JSON, and because it will simply be forwarded to another component, the application has no reason to interpret the content in any way. Is there a way to serialize the custom payload to JSON? 	You can use pickle.dump to dump the pickled object to the open file:\n\nimport pickle\n\nwith open('file.txt', 'r') as f:\n    pickled_object = pickle(f)\n\n\nThen you can dump it to the pickle module.\n	' ')  return the mime part that is the best candidate to be the “ body ” of the message. preferencelist must be a sequence of strings from the set related, html, and plain, and indicates the order of preference for the content type of the part returned. start looking for candidate matches with the object on which the get _ body method is called. if related is not included in preferencelist, consider the root part ( or subpart of the root part ) of any related encountered.	1
"""make an xml file open cv readable"""	\nopen('test.xml', 'r')\n\n	\nimport os\nimport xml.etree.ElementTree as ET\nfrom xml.dom import minidom\nimport cv2\nimport numpy as np\nimport glob\nimport shutil\n\n	0
"""return the number of different values in pandas dataframe as an integer"""	\ndf.apply(lambda x: len(set(x)))\n\n	\n     return len(set(df.values.flatten()))	1
"""find intersection data between series `s1` and series `s2`"""	\ns1.intersection(s2)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n	\ns1.intersection(s2)\ns1.union(s2)\ns1.symmetric_difference(s2)\ns1.difference(s2)\ns1.symmetric_difference(s2)\ns1.symmetric_difference(s2)\ns1.symmetric_difference(s2)\ns1.symmetric_difference(s2)\ns1.symmetric_difference(s2)\ns1.symmetric_difference(s2)\n	1
"""encode `Decimal('3.9')` to a JSON string"""	\n     return json.dumps(decimal_to_json(decimal))	\n\nimport json\n\n	0
"""use Instagram API in Python to upload images to my own account"""	\nrequests.post('https://api.instagram.com/v1/media/{media_id}/upload',\n              json={'media_id': '{media_id}'},\n  `content-type`='multipart/form-data')\n\nI get the following error:\n{'error': 'invalid_request', 'error_description': 'Invalid request'}\n\nA:\n	\nimport requests\nimport json\nurl = 'https://api.instagram.com/v1/users/self/media/recent/?access_token=ACCESS_TOKEN'\nresponse = requests.get(url)\ndata = json.loads(response.text)\nfor media in data['data']:\n    print media['source']\n    print media['owner']['username']\n    print media['owner']['profile_image_url']\n    print media['owner']['full_name']\n    print	1
"""download the latest dataset(.csv) with an automatic Python script from Nasdaq"""	\nos.system('python -m pandas.read_csv file.csv')\n\n	\nimport urllib2\nurl = 'http://www.nasdaq.com/symbol/aapl/historical'\nresponse = urllib2.urlopen(url)\ndata = response.read()\nwith open('aapl.csv', 'w') as f:\n    f.write(data)\nprint 'Downloaded aapl.csv'\n	1
"""stop asking for input after reaching a specific amount of elements in a list"""	\nlist(itertools.islice(it, len(it)))\n\n	\nimport random\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1, 100), 10)\nrandom.sample(range(1	1
"""save variable into a file (like print but into file)"""	\nimport pickle\npickle.dump(variable, file)\nfile.close()\nfile = open("file.txt", "w")\npickle.dump(variable, file)\nfile.close()\nfile = open("file.txt", "r")\nvariable = pickle.load(file)\nfile.close()\nprint variable\nfile = open("file.txt", "w")\npickle.dump(variable, file)\nfile.close()\nfile = open("file.txt", "r")\nvariable = pickle.load(file)\nfile.	\nimport os\nimport sys\nprint("Hello World")\nos.system("echo %s > file.txt" % "Hello World")\nsys.stdout.write("Hello World")\nsys.stdout.flush()\nsys.stdout.close()\nos.system("echo %s > file.txt" % "Hello World")\nsys.stdout.write("Hello World")\nsys.stdout.flush()\nsys.stdout.close()\nos.system("echo %s > file.txt" % "Hello World")\nsys.stdout.write("	1
"""count most frequent 100 words in column 'text' of dataframe `df`"""	\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100')\n\ndf['text'].str.count('100	\ndf['text'].apply(lambda x: x.split()).apply(lambda x: collections.Counter(x)).apply(lambda x: x.most_common(100))\ndf['text'].apply(lambda x: x.split()).apply(lambda x: collections.Counter(x)).apply(lambda x: x.most_common(100))\n\n	1
"""read from files which has tfrec extension in tensorflow"""	\ntf.io.gfile.GFile('/tmp/tfrec.tfrec', 'rb').read()\n\n	\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.lines as lines\nfrom skimage.measure import find_contours\nfrom skimage.measure import approximate_polygon\nfrom skimage.transform import resize\nfrom skimage.morphology import binary_dilation, binary_erosion, binary_closing\nfrom skimage.filters import gaussian\nfrom skimage.segment	0
"""print elements of list `list` seperated by tabs `\t`"""	\n\nfrom __future__ import print_function\n\nimport sys\nimport os\nimport re\nimport collections\nimport itertools\nimport itertools.count\nimport operator\nimport operator.itemgetter\nimport operator.itemgetter_set\nimport operator.lt\nimport operator.lt_\nimport operator.gt\nimport operator.gt_\nimport operator.lt_gt\nimport operator.lt_gt_\nimport operator.gt_gt\nimport operator.lt_gt_gt\nimport operator.lt_gt_gt_\n\nfrom. import _print_list_se	\n\nimport sys\n\ndef print_elements_of_list_separated_by_tabs(list, tabsize=8):\n    """print elements of list `list` separated by tabs `\t`"""\n    for element in list:\n        print(element, end=tabsize)\n\nif __name__ == "__main__":\n    print_elements_of_list_separated_by_tabs([1, 2, 3, 4, 5, 6, 7, 8, 9])	1
"""count a list of words from a list in python"""	\n\nimport re\nimport sys\nimport os\nimport time\nimport random\nimport string\nimport itertools\n\nfrom collections import defaultdict\nfrom collections import Counter\n\nfrom. import _\n\n	\nimport collections\nwords = ['cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog	1
"""obtain data from a public google sheets using python"""	\n\nimport os\nimport sys\nimport urllib2\nimport urllib\nimport httplib\nimport urllib2\nimport urllib\nimport urllib.request\nimport urllib.error\nimport httplib\nimport httplib.request\nimport httplib.poolmanager\nimport httplib.request\nimport httplib.request\nimport httplib.poolmanager\nimport httplib.request\nimport httplib.poolmanager\nimport httplib.request\nimport httplib.poolmanager\nimport httplib.request\n	\nservice.spreadsheets().values('Sheet1')\n\n	1
"""convert a date which maybe in any format to a specific format in python"""	\n\nimport re\nimport datetime\nimport calendar\nimport time\nimport json\nimport logging\nimport requests\nimport dateutil.parser\nimport dateutil.tz\nfrom dateutil.parser import parse\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.rrule import rrule, DAILY, HOURLY, MINUTELY, SECONDLY, MO, TU, WE, TH, FR, SA, SU\nfrom dateutil.tz import tzlocal\nfrom dateutil.tz import tzutc\nfrom dateutil.tz import tzoffset\n	\ndatetime.datetime.strptime('01/01/2000', '%d/%m/%Y')\n\n	1
"""convert scalar `x` to array"""	\nx = np.array(x)\n\nprint(x)\n\n	\n\nimport numpy as np\n\nfrom scipy.sparse import csr_matrix\n\nfrom..utils import check_array\nfrom..utils.misc import is_array_like	0
"""create a flattened list from multi-levels using recursion in Python"""	\n[item for sublist in [[1, 2, 3], [4, 5, 6]] for item in sublist]\n	\nlist(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list(map(list, list	0
"""generate all possibilities of objects of 2 dimensions"""	\n\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.animation as animation\nfrom matplotlib.animation import FuncAnimation\nimport math\n\n	\n[(x, y) for x in range(3) for y in range(3)]\n\n	1
"""get this type of output in python in string"""	\nprint(type(output))\n	\n         return self.__class__.__name__\n\n     def __repr__(self):\n         return self.__class__.__name__\n\n     def __str__(self):\n         return self.__class__.__name__\n\n     def __call__(self, *args, **kwargs):\n         return self.__class__(*args, **kwargs)\n\n     def __getattr__(self, item):\n         return self.__class__(item)\n\n     def __getitem__(self, item):\n         return self.__class	0
"""read a file line by line from S3 parquet, filter and save line by line to another S3 bucket"""	\nimport boto3\nimport pandas as pd\nimport io\nimport pandas.io.parquet as pq\nimport boto3.s3\nimport boto3.session\ndef read_file(filename):\n    s3 = boto3.client('s3')\n    bucket = s3.get_bucket('my_bucket')\n    file = bucket.get_key(filename)\n    reader = pq.ParquetReader(file)\n    for line in reader:\n    	\nimport boto3\nimport json\nimport os\nimport time\nimport sys\nimport logging\nimport datetime\nimport re\nimport logging\nimport datetime\nimport boto3\nimport boto3.s3\nimport boto3.s3.connection\nimport boto3.s3.connection_to_region\nimport boto3.s3.connection_to_region.connection_to_region_aws\nimport boto3.s3.connection_to_region.connection_to_region_aws.connection_to_region_aws_aws\nimport b	0
"""get probability and label prediction at the same time using sklearn"""	\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error	\npredict(model, X_test)\npredict(model, X_test, verbose=True)\npredict(model, X_test, verbose=True, return_type='multiclass')\npredict(model, X_test, verbose=True, return_type='multiclass', multi_output=True)"""\npredict(model, X_test)\npredict(model, X_test, verbose=True)\npredict(model, X_test, verbose=True, return_type='multiclass')\np	1
"""Round number `answer` to 2 precision after the decimal point"""	\nanswer = int(input("Enter a number: "))\nanswer = round(answer, 2)\nprint("Your answer is: ", answer)\n	\nimport math\nprint round(math.pi, 2)\n	1
"""count non zero values in each column in pandas data frame"""	\ndf.groupby(['A', 'B', 'C'])['D'].transform('count')\n\ndf.groupby(['A', 'B', 'C'])['D'].transform('sum')\n\ndf.groupby(['A', 'B', 'C'])['D'].transform('sum')\n\ndf.groupby(['A', 'B', 'C'])['D'].transform('sum')\n\ndf.groupby(['A', 'B', 'C'])['D'].transform('sum')\n\ndf.	\nimport pandas as pd\nimport numpy as np\n\nfrom pandas import DataFrame, Series, Index, concat, concat_series, concat_frame, concat_dict, concat_list, concat_dict_list, concat_dict_to_list, concat_dict_to_dict, concat_dict_to_dict_list, concat_dict_to_dict_to_list, concat_dict_to_dict_to_dict_list, concat_dict_to_dict_to_dict_to_	1
"""get the last key of dictionary `dict`"""	\ndict.pop('key')\n\nprint(dict.keys())\n\nOutput:\n['key', 'key2', 'key3', 'key4']\n\n	\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict.keys()[-1]\ndict	1
"""search for string that matches regular expression pattern '(?<!Distillr)\\\\AcroTray\\.exe' in string 'C:\\SomeDir\\AcroTray.exe'"""	\n\nimport re\nimport os\nimport sys\nimport time\nimport datetime\nimport subprocess\nimport logging\nimport argparse\nimport threading\nimport queue\nimport multiprocessing\nimport signal\nimport traceback\nimport psutil\nimport threading\nimport multiprocessing\nimport signal\nimport threading\nimport multiprocessing\nimport signal\nimport threading\nimport multiprocessing\nimport signal\nimport threading\nimport multiprocessing\nimport signal\nimport threading\nimport multiprocessing\nimport signal\nimport threading\nimport multiprocessing\n	\nre.search('(?<!Distillr)\\\\AcroTray\\.exe', 'C:\\SomeDir\\AcroTray.exe')\n\nA:\n\nYou can use re.findall() to find all matches in a string:\nre.findall('(?<!Distillr)\\\\AcroTray\\.exe', 'C:\\SomeDir\\AcroTray.exe')\n\nThis will return a list of all matches in the string 'C:\\SomeDir\\AcroTray.exe'.\nIf you want to find	1
"""use 2 numpy arrays as dataset for denoising autoencoder, and further split them into train and test sets"""	\nnp.random.shuffle(np.concatenate((x_train, x_test)))\nnp.random.shuffle(np.concatenate((y_train, y_test)))\nx_train, x_test, y_train, y_test = x_train[:int(len(x_train) * 0.8)], x_train[int(len(x_train) * 0.8):], y_train[:int(len(y_train) * 0.8)], y_train[int(len(y	\nimport numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport math\nimport os\nimport sys\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.ker	0
"""Split a string `x` by last occurrence of character `-`"""	\nx.split('-')[-1]\n\n	\n\nimport re\n\nfrom collections import defaultdict\n\nfrom. import _split_regex\n\n	0
"""filter a dataframe for a given time range"""	\n     return df[(df.index >= start) & (df.index <= end)]	\ndf.loc[(df['Date'] >= '2010-01-01') & (df['Date'] <= '2010-12-31')]\ndf.loc[(df['Date'] >= '2011-01-01') & (df['Date'] <= '2011-12-31')]\ndf.loc[(df['Date'] >= '2012-01-01') & (df['Date'] <= '2012-12-31')]\ndf.loc[(df['Date'] >= '2013-01-01') & (df['Date'] <= '2013-12	1
"""print top words from wordcloud"""	\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import Tf	\nimport os\nimport sys\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\nimport matplotlib.patches as mpatches\n\ndef main():\n     """main function"""\n     if len(sys.argv)!= 2:\n         print("Usage: python3 wordcloud.py <file_path>")\n         exit(1)\n\n     file_path = sys.argv[1]\n     if not os.path	1
"""get open price for NASDAQ in IBKR python API"""	\n\nimport json\nimport logging\nimport os\nimport time\nimport urllib\n\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.files.uploadedfile import SimpleUploadedFile\nfrom django.core.paginator import Paginator, EmptyPage, PageNotAnInteger\nfrom django.core.paginator import PaginatorResult\nfrom django.core.paginator import PaginatorPagination\nfrom django.core.paginator import PaginatorPagination\nfrom	\nimport ibapi\nimport time\nfrom ibapi.common import *\nfrom ibapi.ticktype import *\nfrom ibapi.order import *\nfrom ibapi.contract import *\nfrom ibapi.order_state import *\nfrom ibapi.execution import Execution\nfrom ibapi.execution import ExecutionFilter\nfrom ibapi.commission_report import CommissionReport\nfrom ibapi.scanner import ScannerSubscription\nfrom ibapi.ticktype import *\nfrom ibapi.tag_value import TagValue\nfrom ibapi.common import *\nfrom ibapi.order_	1
"""create a document with horizontal page orientation using google doc api"""	\nimport os\nimport json\nimport requests\nimport logging\nimport datetime\nfrom. import utils\nfrom. import config\nfrom. import constants\nfrom. import utils\nfrom. import exceptions\nfrom. import utils\nfrom. import constants\nfrom. import utils\nfrom. import exceptions\nfrom. import constants\nfrom. import utils\nfrom. import constants\nfrom. import utils\nfrom. import exceptions\nfrom. import constants\nfrom. import utils\nfrom. import constants\nfrom. import utils\nfrom. import exceptions\nfrom. import constants\nfrom. import	\nservice.files().create(body=open('test.html', 'rb'))\n\n	1
"""write a python program to print the sum of a string of numbers that are separated by a comma"""	\nsum(map(int, input().split(",")))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int, input().split()))\nsum(map(int,	\nprint(sum(map(int, input().split(','))))\n	1
"""run a loop by interlinking two lists"""	\nfor i in range(10):\n    for j in range(10):\n        print(i, j)\n\n	\nfor i in range(len(list1)):\n    for j in range(len(list2)):\n        print(list1[i], list2[j])\n    print("\n")\n    \nfor i in range(len(list1)):\n    for j in range(len(list2)):\n        print(list2[j], list1[i])\n    print("\n")\n    \nfor i in range(len(list1)):\n    for j in range(len(list2)):\n        print(list1[	1
"""get a list of installed windows fonts using python"""	\n[(name, size, style) for name, size, style in list(font.families()) if style =='regular']\n	\nos.system('fonts')\n\n	1
"""allow spaces in the default django user model username"""	\nUser.USERNAME_FIELD = 'username'\nUser.REQUIRED_FIELDS = []\nUser.objects.create_user(username='user', password='password')\nUser.objects.create_user(username='user', password='password')\nUser.objects.create_user(username='user', password='password')\nUser.objects.create_user(username='user', password='password')\nUser.objects.create_user(username='user', password='password')\nUser.objects.create_user(username='user', password='password')\nUser.	\nUser.username = 'username'\n\nA:\n	1
"""get a random 4 digit number in python, from 0000-9999"""	\nimport random\nrandom.randint(0, 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999	\nimport random\nimport string\nimport sys\n\n	0
"""run a python file on button click in tkinter"""	\n\nimport tkinter as tk\nfrom tkinter import ttk\nfrom tkinter import messagebox\nimport os\nimport sys\nimport subprocess\nimport time\nimport threading\nimport queue\nimport logging\nimport logging.handlers\nimport logging.config\nimport logging.handlers\nimport logging.config\nimport logging.handlers\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport logging.config\nimport	\n\nimport os\nimport sys\nimport time\nimport tkinter as tk\n\nfrom tkinter import *\nfrom tkinter import messagebox\nfrom tkinter import ttk\nfrom tkinter import messagebox\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import messagebox\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import ttk\nfrom tkinter import	1
"""find a value within nested json 'data' where the key inside another key 'B' is unknown."""	\n\nimport json\nimport re\n\nfrom django.core.exceptions import ValidationError\nfrom django.core.files.uploadedfile import SimpleUploadedFile\nfrom django.core.files.storage import default_storage\nfrom django.core.files.storage.base import Storage\nfrom django.core.files.storage.base import StorageError\nfrom django.core.files.storage.base import StorageError\nfrom django.core.files.storage.base import StorageError\nfrom django.core.files.storage.base import StorageError\nfrom	\nimport json\ndata = json.loads(data)\nprint(data['B']['C']['D'])\n	1
"""treat a `networkx.digraph` as un-directed"""	\nimport networkx as nx\nG = nx.Graph()\nG.add_edge(1, 2)\nG.add_edge(1, 3)\nG.add_edge(2, 3)\nG.add_edge(3, 4)\nG.add_edge(4, 5)\nG.add_edge(5, 6)\nG.add_edge(6, 7)\nG.add_edge(7, 8)\nG.add_edge(8, 9)\nG.add_edge(9, 10)\nG.	\nnetworkx.digraph(directed=False)\n\n	1
"""converting two lists `[1, 2, 3]` and `[4, 5, 6]` into a matrix"""	\nmatrix = [[1, 2, 3], [4, 5, 6]]\nmatrix\nmatrix[0]\nmatrix[0][0]\nmatrix[0][1]\nmatrix[0][2]\nmatrix[1]\nmatrix[1][0]\nmatrix[1][1]\nmatrix[1][2]\nmatrix[0][0] * matrix[1][0]\nmatrix[0][1] * matrix[1][1]\nmatrix[0][2] * matrix[1][2]\nmat	\n     matrix = []\n     for i in range(len(matrix_a)):\n         matrix.append([])\n         for j in range(len(matrix_b)):\n             matrix[i].append(matrix_a[i] * matrix_b[j])\n     return matrix	1
"""send pytest coverage report via email"""	\n\nfrom __future__ import absolute_import\n\nimport os\nimport sys\nimport time\nimport unittest\n\nfrom pip._vendor import pkg_resources\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.packaging.version import parse as parse_version\nfrom pip._vendor.requests.adapters import HTTPAdapter\nfrom pip._vendor.requests.packages.urllib3 import urlopen\nfrom pip._vendor.requests.packages.urllib3.exceptions import InsecureRequestWarning	\nsend_email('pytest coverage report', '<html><body>' + html_body + '</body></html>')\n	1
"""open widget, have it do something, and close by itself"""	\n\nimport os\nimport sys\nimport time\nimport tkinter as tk\nfrom tkinter import ttk\nfrom tkinter import filedialog\nfrom tkinter import messagebox\n\nfrom. import util\nfrom. import config\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import util\nfrom. import	\nfrom Tkinter import *\nroot = Tk()\nroot.withdraw()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy()\nroot.destroy	1
"""find which downscaling algorithm used"""	\nimport cv2\nimport numpy as np\nimg = cv2.imread('image.jpg',0)\nimg = cv2.resize(img,(0,0),fx=0.5,fy=0.5)\nimg = cv2.resize(img,(0,0),fx=2,fy=2)\nimg = cv2.resize(img,(0,0),fx=4,fy=4)\nimg = cv2.resize(img,(0,0),fx=8,fy	\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.nn.modules.utils import _pair\n\nfrom. import resnet\nfrom. import xception\nfrom. import mobilenetv2\nfrom. import shufflenetv2\nfrom. import shufflenetv2_x1_5\nfrom. import shufflenetv2_x2_0\nfrom. import shufflenetv2_x3_0\nfrom. import shufflenetv	0
"""return a 401 unauthorized in django"""	\n         return Response(\n             {\n                 "detail": "Not authenticated. Please log in to continue."\n             },\n             status=status.HTTP_401_UNAUTHORIZED\n         )	\nresponse = HttpResponse(status=401)\nresponse['Content-Type'] = 'application/json'\nreturn response\n\nA:\n\nYou can use the following code to return a 401 Unauthorized response in django:\nfrom django.http import HttpResponse\ndef my_view(request):\n    response = HttpResponse(status=401)\n    response['Content-Type'] = 'application/json'\n    return response\n\nA:\n\nYou can use django-allauth for authentication.\nfrom allauth.account.	0
"""read string in sound with python without create mp3 file just with command line"""	\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals	\nimport os\nimport sys\nimport time\nimport subprocess\nimport threading\nimport pygame\nfrom pygame.locals import *\nfrom pygame.compat import geterror\nfrom pygame.mixer import Sound, init, quit\n\n	1
"""make the game restart (python turtle snake game)"""	\nimport turtle\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset()\nturtle.reset	\n\nimport turtle\nimport random\nimport math\nimport time\nimport sys\nimport os\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\nimport random\nimport math\nimport turtle\n	0
"""convert a date format (YYYY-MM-DD) to (YYYY,MM,DD) in Python"""	\ndatetime.datetime.strptime('2012-01-01', '%Y-%m-%d').strftime('%Y,%m,%d')\n\n	\ndatetime.datetime.strptime('2013-12-25', '%Y-%m-%d')\n\n	0
"""group a list of dicts `LD` into one dict by key"""	\n\nimport collections\nimport copy\nimport itertools\nimport operator\nimport re\nimport sys\n\nfrom. import _base\nfrom. import _base_dict\nfrom. import _base_list\nfrom. import _base_set\nfrom. import _base_tuple\nfrom. import _base_dict_list\nfrom. import _base_dict_set\nfrom. import _base_dict_tuple\nfrom. import _base_dict_list_set\nfrom. import _base_dict_tuple_set\nfrom. import _base_dict_set_	\n     return {k: v for d in LD for k, v in d.items()}	1
"""save a pandas dataframe to csv in overwrite mode"""	\ndf.to_csv('filename.csv', mode='a')\ndf.to_csv('filename.csv', mode='w')\ndf.to_csv('filename.csv', mode='a')\ndf.to_csv('filename.csv', mode='w')\ndf.to_csv('filename.csv', mode='a')\ndf.to_csv('filename.csv', mode='w')\ndf.to_csv('filename.csv', mode='a')\ndf.to_csv('filename.csv', mode='w')\ndf.to_csv('filename	\nimport pandas as pd\nimport numpy as np\nimport os\nimport csv\nimport sys\nimport time\nimport random\nimport math\nimport copy\nimport copy_reg\nfrom collections import defaultdict\nfrom collections import Counter\nfrom itertools import chain\nfrom itertools import islice\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools import groupby\nfrom itertools	0
"""I get summary statistics by rows while using Pandas df.describe() ,"""	\ndf.describe(axis=1)\n\n	\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport scipy.special as special\nimport scipy.optimize as opt\nimport scipy.stats as stats\nfrom scipy.stats import norm\nfrom scipy.stats import ttest_ind\nfrom scipy.stats import ttest_rel\nfrom scipy.stats import ttest_1samp\nfrom scipy.stats import ttest_	0
"""run two different neural network on two GPUs"""	\n\nimport os\nimport sys\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.distributed import DistributedDataParallel\nfrom torch.utils.data.distributed import DistributedDataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.utils.data.distributed import DistributedBatchSampler\nfrom torch.utils.data.distributed	\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport tensorflow.contrib.eager.python_eager as tfe_py\nimport tensorflow.contrib.eager.python_eager.python_ops as tfe_py_ops\nimport tensorflow.contrib.eager.python_eager.python_ops.python_ops as tfe_py_ops\nimport tensorflow.contrib.eager.python_eager.python_ops.python	1
"""check for NaN in any data structure in python"""	\nimport math\nimport numpy as np\nx = np.array([1,2,3,4,5,6,7,8,9,10])\nx[x == math.nan]\nx[np.isnan(x)]\nx[np.isnan(x) == False]\nx[np.isnan(x) == True]\nx[np.isnan(x) == False]\nx[np.isnan(x) == False]\nx[np.isnan(x) == False]\nx[np.isnan(	\nnp.isnan(np.array([1, 2, 3, np.nan, 4, 5, 6, 7, 8, 9]))\n\n	1
"""remove items from a list A that present in list B (with the removal of duplicates )"""	\n     return [x for x in A if x not in B]	\n\nimport copy\n\nfrom collections import deque\n\nfrom. import _base\nfrom. import _base_utils\nfrom. import _base_utils_list\nfrom. import _base_utils_set\nfrom. import _base_utils_dict\nfrom. import _base_utils_set_dict\nfrom. import _base_utils_dict_dict\nfrom. import _base_utils_dict_set\nfrom. import _base_utils_dict_set_dict\nfrom. import _base_utils_dict_dict_set\nfrom. import _base_utils	0
"""select the last column of dataframe `df`"""	\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib.cm as cm\nimport matplotlib.dates as mdates\nimport matplotlib.dates as mdates_\nimport matplotlib.ticker as mticker\nimport matplotlib.dates as mdates_\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates_\nimport matplotlib.ticker as mticker\nimport matplotlib.	\ndf.iloc[:, -1]\ndf.columns = df.iloc[:, -1]\ndf.columns = df.columns.str.replace(' ', '_')\ndf.columns = df.columns.str.replace('-', '_')\ndf.columns = df.columns.str.replace('/', '_')\ndf.columns = df.columns.str.replace('\\', '_')\ndf.columns = df.columns.str.replace('(', '_')\ndf.column	1
"""use K-fold cross validation in TensorFlow"""	\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nkf = KFold(n_splits=5)\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model.fit(X_train, y_train)\n    print("Accuracy: %.2f"	\ntf.keras.models.KMeans(n_clusters=3).fit(x)\n\n	0
"""return the day of an inputed date"""	\n     return date.weekday()	\ndatetime.datetime.strptime('2014-01-01', '%Y-%m-%d')[0]\n\nA:\n	1
"""remove items from a list A that present in list B (with the removal of duplicates )"""	\n     return [x for x in A if x not in B]	\nA = [1, 2, 3, 4, 5]\nB = [1, 2, 3, 4, 5]\nA.remove(B)\nA\nA = [1, 2, 3, 4, 5]\nA.remove(B)\nA\nA = [1, 2, 3, 4, 5]\nA.remove(B)\nA\nA = [1, 2, 3, 4, 5]\nA.remove(B)\nA\nA = [1, 2, 3, 4, 5]\nA.remove(B)\n	0
"""add a header to a csv file"""	\nimport pandas as pd\ndf = pd.read_csv('file.csv')\ndf.to_csv('file.csv.header')\ndf.to_csv('file.csv')\ndf.to_csv('file.csv.header')\ndf.to_csv('file.csv')\ndf.to_csv('file.csv.header')\ndf.to_csv('file.csv')\ndf.to_csv('file.csv.header')\ndf.to_csv('file.csv')\ndf.to_csv('file.csv.	\nimport csv\nfile = open("file.csv", "a")\nwriter = csv.writer(file)\nwriter.writerow(["name", "age"])\nfile.close()\nfile = open("file.csv", "a")\nwriter = csv.writer(file)\nwriter.writerow(["name", "age"])\nfile.close()\nfile = open("file.csv", "a")\nwriter = csv.writer(file)\nwriter.writerow(["name", "age"])\nfile.close()\nfile = open	1
"""extract text from a pdf file"""	\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageFont\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom P	\npdf.extractText(pdf.open('test.pdf'))\n\n	1
"""find area coordinates of a invoice table in pdf file using python"""	\n\nimport os\nimport sys\nimport re\nimport shutil\nimport time\nimport math\nimport numpy as np\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport os\nimport math\nimport os\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport argparse\nimport os.path\nimport csv\nimport argparse\nimport os	\n\nimport PyPDF2\nimport re\nimport os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n	1
import itertools\nimport ast\nimport string\nimport re\nimport google\n\ndef remove():\n    """remove all special characters, punctuation and spaces from a string `mystring` using regex"""\n    	re.sub('[^a-zA-Z0-9\s]', '', mystring)\n\n	\nre.sub('[^a-zA-Z0-9\s]', '', mystring)\n\n	1
"""get json data from restful service 'url'"""	\nimport requests\nresponse = requests.get('http://www.example.com/api/v1/users/1')\nprint(response.json())\n	response = urllib.request.urlopen('url')\n    data = json.loads(response.read().decode('utf-8'))\n    print(data)\n\n	1
"""create a static file in django"""	\nfrom django.conf import settings\nsettings.STATIC_URL = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STATIC_ROOT = '/static/'\nsettings.STAT	\nfrom django.conf import settings\nfrom django.http import HttpResponse\n	1
"""get all the classes in a module"""	\nimport inspect\ninspect.getmembers(module, inspect.isclass)\n[(name, obj) for name, obj in inspect.getmembers(module) if inspect.isclass(obj)]\n[obj for name, obj in inspect.getmembers(module) if inspect.isclass(obj)]\n[obj for name, obj in inspect.getmembers(module) if inspect.isclass(obj) and name!='module']\n[obj for name, obj in inspect.getmembers(module) if inspect.isclass(obj) and name!='module']\n[obj	\nimport inspect\ninspect.getmembers(module)\ninspect.getmembers(module, inspect.ismethod)\ninspect.getmembers(module, inspect.isclass)\ninspect.getmembers(module, inspect.isfunction)\ninspect.getmembers(module, inspect.ismethod)\ninspect.getmembers(module, inspect.isbuiltin)\ninspect.getmembers(module, inspect.isabstract)\ninspect.getmembers(module, inspect.isabstractclass)\ninspect.getmembers(module, inspect.isclass	1
"""convert a hex-string representation to actual bytes"""	\nhex_string = '\x01\x02\x03\x04'\nhex_string.decode('hex')\nb'\x01\x02\x03\x04'\nb'\x01\x02\x03\x04'\nb'\x01\x02\x03\x04'\nb'\x01\x02\x03\x04'\nb'\x01\x02\x03\x04'\nb'\x01\x02\x03\x04'\nb'	\nbytes.hex('0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0x0	0
"""use Postgresql Array field in Tortoise-ORM"""	\nclass User(Model):\n    name = CharField(max_length=50)\n    age = IntField()\n    friends = ArrayField(IntField())\n    friends.add_listener(on_set_value)\n    friends.add_listener(on_pre_save)\n    friends.add_listener(on_post_save)\n    friends.add_listener(on_pre_delete)\n    friends.add_listener(on_post_delete)\n    def __str__(self):\n        return self.name\n    	\ntortoise.connect('test_db')\n\n	0
import requests\nimport subprocess\nimport io\nimport json\nimport os\n\ndef open():\n    """open a file `Output.txt` in append mode"""\n    	f = open('Output.txt', 'a')\n\n	\nwith open('Output.txt', 'a') as f:\n    f.write(str(data))\n    f.write('\n')\n    f.close()\n    f = open('Output.txt', 'r')\n    print(f.read())\n    f.close()\n    f = open('Output.txt', 'w')\n    f.write(str(data))\n    f.close()\n    f = open('Output.txt', 'r')\n    print(f.read())\n    f.close()\n    f = open('	0
"""get rid of None values in dictionary `kwargs`"""\n   	dict((k, v) for k, v in kwargs.items() if v is not None)\n\n	    def func(**kwargs):\n\n        return kwargs\n\n    return func\n	0
How to find duplicate names using pandas?	    x = pd.read_csv('../data/names.csv')\n\n    print(x.name.value_counts())\n\n    print(x.name.value_counts().index)\n\n    print(x.name.value_counts().values)\n\n    print(x.name.value_counts().index.values)\n\n    print(x.name.value_counts().values.values)\n\n    print(x.name.value_counts().index.values.values)\n\n    print(x.name.value_counts().values.values.values)\n\n    print(x.name.value_counts().index.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values.values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values.values.values.values.values)\n\n    print(x.name.value_counts().values.values.values.values.values.values.values.values.values)\n\n    print(x.name.value_counts().index.values.values.values.values.values.values.values.\n	\nx['name'].value_counts().index[x['name'].value_counts() > 1]\n\n	1
"""unzip the list `[('a', 1), ('b', 2), ('c', 3), ('d', 4)]`"""\n   	zip(*[('a', 1), ('b', 2), ('c', 3), ('d', 4)])\n\n	    myList = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n\n    print(list(zip(*myList)))\n	1
String Slicing Python	    s = "This is a string with a comma,,"\n\n    print(s.rstrip(","))\n	\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]\ns = s[:-1]	1
"""erase all the contents of a file `filename`"""\n   	open(filename, 'w').close()\n\n	\nos.remove(filename)\n\n	0
"""Split a string by a delimiter in python"""	\nprint(re.split('\\s+', 'a b c d e f g h i j k l m n o p q r s t u v w x y z'))\n	re.split('\\W+', 'This is a string with a delimiter')\n\n	1
"""Extract brackets from string `s`"""\n   	re.findall('\\[(.*?)\\]', s)\n\n	\nre.findall('\\[(.*?)\\]', s)\n\n	1
"""Convert  DateTime column 'date' of pandas dataframe 'df' to ordinal"""	\ndf['date'].apply(lambda x: x.toordinal())\ndf['date'] = df['date'].apply(lambda x: x.toordinal())\n\ndf['date'] = df['date'].apply(lambda x: datetime.datetime.fromordinal(x))\ndf['date'] = df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\ndf['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, '	df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n    df['date'] = df['date'].map(lambda x: x.toordinal())\n\ndef Convert():\n    """Convert  DateTime column 'date' of pandas dataframe 'df' to ordinal"""\n    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n    df['date'] = df['date'].map(lambda x	1
"""Send a post request with raw data `DATA` and basic authentication with `username` and `password`"""	\nrequest.post('http://httpbin.org/post', data=DATA, auth=('username', 'password'))\n	\nimport requests\nresponse = requests.post(url, data=DATA, auth=HTTPBasicAuth(username, password))\nprint(response.text)\n	0
determine the variable type	    v = input("Enter a number: ")\n\n    if v.isdigit():\n\n        print("It's a digit")\n\n    elif v.isalpha():\n\n        print("It's a letter")\n\n    else:\n\n        print("It's a string")\n\n    return v\n	\ntype(v)\ntype(v) == int\ntype(v) == float\ntype(v) == str\ntype(v) == bool\ntype(v) == list\ntype(v) == tuple\ntype(v) == set\ntype(v) == dict\ntype(v) == NoneType\ntype(v) == type(None)\ntype(v) == object\ntype(v) == type(None)\ntype(v) == type(None)\ntype(v) == type(None)\ntype(v) == type(None)\ntype	0
"""convert unicode string u"{'code1':1,'code2':1}" into dictionary"""	\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':1}\n{'code1':1,'code2':	    ustring = u"{'code1':1,'code2':1}"\n\n    print(ustring.encode("utf-8").decode("utf-8"))\n	1
"""replace all elements in array `A` that are not present in array `[1, 3, 4]` with zeros"""	\nA = [1, 3, 4]\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [1, 3, 4]] = 0\nA\nA[A!= [	\na = [1, 3, 4]\na[a.index(1):] = [0] * (len(a) - a.index(1))\nprint(a)\na[a.index(1):] = [0] * (len(a) - a.index(1))\n	1
"""convert unicode string `s` to ascii"""	\ns.encode('ascii', 'ignore')\n\n	\nimport unicodedata\ns = u'\u0627\u0631\u0627\u062f'\nprint unicodedata.normalize('NFD', s)\n	1
"""join together with "," elements inside a list indexed with 'category' within a dictionary `trans`"""	\nfor key, value in trans.items():\n    trans[key] = ','.join(value)\nprint(trans)\n	\ntrans.items()[category].join(',')\n\nprint(trans)\n\nOutput:\n{'category': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34	0
Python how to write to a binary file?	    newFileBytes = b'\x00\x01\x02\x03\x04\x05\x06\x07\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f'\n\n    newFile = 'newFile.bin'\n\n    with open(newFile, 'wb') as f:\n\n        f.write(newFileBytes)\n\n    print('Wrote', len(newFileBytes), 'bytes to', newFile)\n\n    return newFile\n	\nwith open(newFile, 'wb') as f:\n    f.write(newFileBytes)\n    f.close()\nwith open(newFile, 'rb') as f:\n    newFileBytes = f.read()\n    f.close()\nwith open(newFile, 'wb') as f:\n    f.write(newFileBytes)\n    f.close()\nwith open(newFile, 'rb') as f:\n    newFileBytes = f.read()\n    f.close()\nwith open(newFile, 'wb') as f	0
"""create a list containing each two adjacent letters in string `word` as its elements"""\n   	[word[i:i + 2] for i in range(0, len(word), 2)]\n\n	\nimport re\ns = "I am a dog"\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.findall(r'\w+', s)\nre.find	0
"""get the last key of dictionary `dict`"""\n   	dict.keys()[-1]\n\n	    def func(dict):\n\n        return list(dict.keys())[-1]\n\n    return func\n	1
"""find all words in a string `mystring` that start with the `$` sign"""	\nre.findall('^\\$(\\w+)', mystring)\n	\nimport re\nmystring = '$this is a $string'\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\	1
"""convert list `[('Name', 'Joe'), ('Age', 22)]` into a dictionary"""	\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age': 22}\n{'Name': 'Joe', 'Age':	\ndict(zip(['Name', 'Age'], [x[0] for x in lst]))\ndict(zip(['Name', 'Age'], [x[1] for x in lst]))\ndict(zip(['Name', 'Age'], [x[0] for x in lst]))[x[1] for x in lst]\ndict(zip(['Name', 'Age'], [x[1] for x in lst]))[x[0] for x in lst]\ndict(zip(['Name', 'Age	1
"""get digits only from a string `aas30dsa20` using lambda function"""	\nimport re\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+', aas30dsa20)\nre.findall(r'\d+	re.findall('\\d+', aas30dsa20)\n\n	1
"""converting list of strings `intstringlist` to list of integer `nums`"""	\nintstringlist = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(i) for i in stringlist]\nnums = [int(	\nimport re\nre.findall(r'\d+', '1,2,3,4,5')\nre.findall(r'\d+', '1,2,3,4,5')\nre.findall(r'\d+', '1,2,3,4,5')\nre.findall(r'\d+', '1,2,3,4,5')\nre.findall(r'\d+', '1,2,3,4,5')\nre.findall(r'\d	0
"""reverse the list that contains 1 to 10"""	\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\na[::-1]\na[::-2]\na[::-3]\na[::-4]\na[::-5]\na[::-6]\na[::-7]\na[::-8]\na[::-9]\na[::-10]\na[::-11]\na[::-12]\na[::-13]\na[::-14]\na[::-15	[x for x in range(10, 0, -1)]\n\n	1
"""join together with "," elements inside a list indexed with 'category' within a dictionary `trans`"""	\ntrans = {'category': ['a', 'b', 'c', 'd'], 'value': [1, 2, 3, 4]}\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category', [])\ntrans.get('category	print(','.join(['{0}'.format(x) for x in list(trans['category'].values)]))\n\n	1
"""convert a raw string `raw_byte_string` into a normal string"""	\nimport string\nraw_byte_string = '\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00	\nimport re\ns = "\\x89\\n"\nre.sub(r'[\x80-\xFF]', '', s)\ns = re.sub(r'[\x80-\xFF]', '', s)\ns = s.decode('utf-8')\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\ns\n	1
"""modify sys.path for python module `subdir`"""	\nimport sys\nsys.path.append('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar()\nsys.path.remove('subdir')\nimport foo\nfoo.bar	\nos.mkdir('apps')\nos.mkdir('__file__')\nos.mkdir('apps/__file__')\n\nprint(os.path.join('apps', '__file__'))\n	0
Removing an item from list matching a substring - Python	    sents = ["@$\tThis is a test", "This is a test", "This is a test", "#This is a test", "This is a test"]\n\n    sents = [s for s in sents if not s.startswith("#")]\n\n    sents = [s for s in sents if not s.startswith("@$\t")]\n\n    print(sents)\n	\nsents = [sent for sent in sents if not sent.startswith("@$")]\nsents = [sent for sent in sents if not sent.startswith("#	1
"""find the index of an element 'MSFT' in a list `stocks_list`"""	\nimport re\nre.search(r'\bMSFT\b',''.join(stocks_list)).start()\nre.search(r'\bMSFT\b',''.join(stocks_list)).end()\nre.search(r'\bMSFT\b',''.join(stocks_list)).group()\nre.search(r'\bMSFT\b',''.join(stocks_list)).group().start()\nre.search(r'\bMSFT\b',''.join(stocks_list)).group().end()\n	    stocks_list = ["GOOG", "MSFT", "AAPL", "AMZN", "FB", "TWTR"]\n\n    print(stocks_list.index("MSFT"))\n	1
"""sum all elements of nested list `L`"""	\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum	\nsum(L)\n\nA:\n\nYou can use itertools.groupby to group the elements of list L by the key 'key' and sum the values of each group:\nsum(itertools.groupby(L, key=lambda x: x[1]))\n\nA:\n\nYou can use itertools.groupby to group the elements of list L by the key 'key' and sum the values of each group:\nsum(itertools.groupby(L, key=lambda x: x[1]))\n\nA:\n\nYou	1
"""Create multidimensional array `matrix` with 3 rows and 2 columns in python"""\n   	matrix = np.zeros((3, 2))\n\n	\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nmatrix = [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]\nmatrix = [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]\nmatrix = [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12	0
Is there a function in Python to split a string without ignoring the spaces?	    mystring = "This is a string. It is split into separate strings."\n\n    print(mystring.split())\n	\ns ='mystring'\ns.split()\ns.split(' ')\ns.split(' ')[1]\ns.split(' ')[1].split()[0]\ns.split(' ')[1].split()[0].split('-')[0]\ns.split(' ')[1].split()[0].split('-')[0].split('.')[0]\ns.split(' ')[1].split()[0].split('-')[0].split('.')[0].split('/')[0]\ns.split	0
"""add a header to a csv file"""	\ncsv.writer('file.csv', delimiter=',', quoting=csv.QUOTE_NONE)\ncsv.writer('file.csv', delimiter=',', quoting=csv.QUOTE_NONE)\ncsv.writer('file.csv', delimiter=',', quoting=csv.QUOTE_NONE)\ncsv.writer('file.csv', delimiter=',', quoting=csv.QUOTE_NONE)\ncsv.writer('file.csv', delimiter=',', quoting=csv.QUOTE_NONE)\ncsv.writer('file.csv	df.to_csv('myfile.csv', header=True)\n\n	1
"""Sort a list of tuples `b` by third item in the tuple"""	\nsorted(b, key=lambda x: x[2])\n\nThis will sort the list `b` by the third item in each tuple in the list `b` in ascending order.\n\n	\nb = [('a', 1), ('b', 2), ('c', 3)]\nb.sort(key=lambda x: x[1])\nb\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x	0
"""read a file `file` without newlines"""	\nfile.read()\n\nprint(file.read())\n\n	    file = input("Enter a file name: ")\n\n    with open(file) as f:\n\n        print(f.read())\n\n    return file\n	1
"""generate all 2-element subsets of tuple `(1, 2, 3)`"""	\n[(1, 2), (1, 3), (2, 3)]\n[(1, 2), (2, 3), (1, 3)]\n[(1, 2), (2, 3), (3, 1)]\n[(1, 2), (2, 3), (3, 2)]\n[(1, 2), (2, 3), (3, 3)]\n[(1, 2), (2, 3), (3, 1), (1, 3)]\n[(1, 2), (2, 3), (3, 2), (1, 3	    print(tuple(itertools.combinations((1, 2, 3), 2)))\n	1
"""split a string `s` with into all strings of repeated characters"""\n   	re.findall('(.)\\1+', s)\n\n	\ns = "abcdefghijklmnopqrstuvwxyz"\ns = s.split()\ns = [s[i:i+3] for i in range(0, len(s), 3)]\ns = [s[i:i+3] for i in range(0, len(s), 3)]\ns = [s[i:i+3] for i in range(0, len(s), 3)]\ns = [s[i:i+3] for i in range(0, len(s), 3)]\ns	0
"""convert a pandas series `sf` into a pandas dataframe `df` with columns `email` and `list`"""	\ndf = pd.DataFrame(sf.values.tolist(), columns=['email', 'list'])\ndf['list'] = df['list'].apply(lambda x: json.loads(x))\ndf['list'] = df['list'].apply(lambda x: list(x.values()))\ndf['list'] = df['list'].apply(lambda x: list(map(int, x)))\ndf['list'] = df['list'].apply(lambda x: list(map(str, x)))\ndf['list'] = df['list	\ndf = df.set_index('email')\ndf.to_frame('list')\ndf.to_frame('list').columns\ndf.to_frame('list').columns.values\ndf.to_frame('list').columns.tolist()\ndf.to_frame('list').columns.tolist().values\ndf.to_frame('list').columns.tolist().tolist()\ndf.to_frame('list').columns.tolist().tolist().tolist()\ndf.to_frame('	0
"""rotate the xtick labels of matplotlib plot `ax` by `45` degrees to make long labels readable"""	\nax.set_xticklabels([45])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xticklabels([])\nax.set_xt	\nplt.xticks(rotation=45)\nplt.show()\nplt.savefig('my_plot.png')\nplt.close()\nplt.show()\nplt.savefig('my_plot.png')\nplt.close()\nplt.show()\nplt.savefig('my_plot.png')\nplt.close()\nplt.show()\nplt.savefig('my_plot.png')\nplt.close()\nplt.show()\nplt.savefig('my_plot	1
"""Sort a list of tuples `b` by third item in the tuple"""	\nb = [('a', 1), ('b', 2), ('c', 3)]\nb.sort(key=lambda x: x[1])\nb\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x: x[1])\nb.sort(key=lambda x	\nb.sort(key=lambda x: x[2])\n\n	1
"""delete all instances of a character 'i' in a string 'it is icy'"""	\nre.sub('i', '', 'it is icy')\n\n	\nprint(s.replace("i", ""))\n	1
"""create a DatetimeIndex containing 13 periods of the second friday of each month starting from date '2016-01-01'"""	\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.relativedelta import relat	\nimport pandas as pd\ndf = pd.read_csv('file.csv')\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.set_index('Date')\ndf.index = pd.to_datetime(df.index)\ndf.index = df.index.normalize()\ndf.index = df.index.tz_localize('UTC')\ndf.index = df.index.tz_convert('US/Eastern')\ndf.index = df.index.tz_localize(	1
Python - how to convert a "raw" string into a normal string	    raw_byte_string = b"\x4a\x4b\x4c"\n\n    print(raw_byte_string.decode("utf-8"))\n	    raw_string = r"This is a raw string."\n\n    print(raw_string)\n	0
"""Update datetime field in `MyModel` to be the existing `timestamp` plus 100 years"""	\nclass MyModel(models.Model):\n    created = models.DateTimeField(auto_now_add=True)\n    updated = models.DateTimeField(auto_now=True)\n    updated_at = models.DateTimeField(auto_now=True)\n    updated_at_plus_100_years = models.DateTimeField(auto_now=True, blank=True)\n    updated_at_plus_100_years = models.DateTimeField(auto_now=True, blank=True)\n	\nfrom django.db import models\nfrom django.utils import timezone\nclass MyModel(models.Model):\n    timestamp = models.DateTimeField(default=timezone.now)\n    def save(self, *args, **kwargs):\n        self.timestamp = timezone.now() + timezone.timedelta(days=100)\n        super(MyModel, self).save(*args, **kwargs)\n    def __str__(self):\n        return self.timestamp.strftime("%Y-%m-%d %	1
"""Append elements of a set to a list in Python"""	\n[x + y for x, y in zip(set(a), b)]\n\nA:\n\nYou can use zip with a list comprehension:\n[x + y for x, y in zip(a, b)]\n\nA:\n\nzip(a, b) returns a list of tuples, so you can use itertools.chain.from_iterable to append elements of a list to a list of tuples:\n[x + y for x, y in zip(a, b)]\n\nA:\n\nzip(a, b) returns a list of tu	a.extend(b)\n\n	1
"""convert a list  into a generator object"""	\nlist(itertools.chain.from_iterable(it))\n\nA:\n\nlist(itertools.chain.from_iterable(it))\n\nis equivalent to:\nlist(itertools.chain.from_iterable(it))\n\nA:\n\nlist(itertools.chain.from_iterable(it))\n\nis equivalent to:\nlist(itertools.chain.from_iterable(it))\n\nA:\n\nlist(itertools.chain.from_iterable(it))\n\nis equivalent to	\ndef generator(lst):\n  for item in lst:\n    yield item\ng = generator([1,2,3])\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext(g)\nnext	1
"""concatenate items of list `l` with a space ' '"""	\n' '.join(l)\n	print(' '.join(l))\n\n	1
"""How to sort dictionaries by keys in Python"""	\nimport operator\nsorted(d.items(), key=operator.itemgetter(0))\nsorted(d.items(), key=operator.itemgetter(1))\nsorted(d.items(), key=lambda x: x[1])\nsorted(d.items(), key=lambda x: x[1], reverse=True)\nsorted(d.items(), key=lambda x: x[1], reverse=True)\nsorted(d.items(), key=lambda x: x[1], reverse=True)\nsorted(d.items(), key	\nsorted(list(o.items()), key=lambda x: x[0])\n\n	1
"""Sum the corresponding decimal values for binary values of each boolean element in list `x`"""	\nsum(map(lambda x: x.decimal, x))\n\n	\nsum(x[(b, b) for b in x if b])\n\n	0
"""use `%s` operator to print variable values `str1` inside a string"""	\nprint('str1 = %s' % str1)\n\n	\nprint('%s' % str1)\n	0
"""Extract brackets from string `s`"""\n   	re.findall('\\[(.*?)\\]', s)\n\n	\ns = '"{}"'\ns[1:-1]\ns[1:-1].replace('"', '')\ns[1:-1].replace('"', '').replace('{', '').replace('}', '')\ns[1:-1].replace('"', '').replace('{', '').replace('}', '').replace('"', '')\ns[1:-1].replace('"', '').replace('{', '').replace('}', '').replace('"', '')\ns[1:-1].replace('"', '').	0
"""Google App Engine execute GQL query 'SELECT * FROM Schedule WHERE station = $1' with parameter `foo.key()`"""\n   	db.execute('SELECT * FROM Schedule WHERE station = $1', 'foo.key()')\n\n	\nimport gql\nclass MyClass(gql.GqlQuery):\n    def __init__(self, *args, **kwargs):\n        super(MyClass, self).__init__(*args, **kwargs)\n        self.parameter = kwargs.get('parameter', None)\n    def execute(self, *args, **kwargs):\n        return super(MyClass, self).execute(*args, **kwargs)\n    def	1
"""Iterate ove list `[1, 2, 3]` using list comprehension"""	\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]	[x for x in [1, 2, 3]]\n\n	1
"""Sum integers contained in strings in list `['', '3.4', '', '', '1.0']`"""	\n[int(x) for x in ['', '3.4', '', '', '1.0']]\n\n	    myList = ['', '3.4', '', '', '1.0']\n\n    print(sum([int(x) for x in myList if x.isdigit()]))\n	1
"""decode string "\\x89\\n" into a normal string"""	\nimport codecs\ncodecs.decode('\\x89\\n', 'rot13')\ncodecs.decode('\\x89\\n', 'rot13','replace')\ncodecs.decode('\\x89\\n', 'rot13', 'backslashreplace')\ncodecs.decode('\\x89\\n', 'rot13', 'xmlcharrefreplace')\ncodecs.decode('\\x89\\n', 'rot13', 'backslashreplace', 'xmlcharrefreplace')\ncodecs.decode	\nraw_string.decode('utf-8')\n\n	1
"""add one to the hidden web element with id 'XYZ' with selenium python script"""	\ndriver.find_element_by_id('XYZ').clear()\ndriver.find_element_by_id('XYZ').send_keys('one')\ndriver.find_element_by_id('XYZ').send_keys('two')\ndriver.find_element_by_id('XYZ').send_keys('three')\ndriver.find_element_by_id('XYZ').send_keys('four')\ndriver.find_element_by_id('XYZ').send_keys('five')\ndriver.find_element_by_id('XY	\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\ndriver = webdriver.Firefox()\ndriver.get("http://www.google.com")\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL + "a")\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL + "x")\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL + "z")\ndriver.	1
"""How to delete all instances of a character in a string in python?"""	\nre.sub('[^a-zA-Z0-9]', '', string)\n\n	\nimport re\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it is icy')\nre.sub('[i]', '', 'it	0
"""convert a pandas series `sf` into a pandas dataframe `df` with columns `email` and `list`"""	\ndf = pd.DataFrame(sf.values.tolist(), columns=['email', 'list'])\ndf['list'] = df['list'].apply(lambda x: json.loads(x))\ndf['list'] = df['list'].apply(lambda x: list(x.values()))\ndf['list'] = df['list'].apply(lambda x: list(map(int, x)))\ndf['list'] = df['list'].apply(lambda x: list(map(str, x)))\ndf['list'] = df['list	\ndf = pd.DataFrame(sf.tolist(), columns=['email', 'list'])\ndf['list'] = df['list'].apply(pd.Series)\ndf['list'] = df['list'].apply(pd.Series)\ndf['list'] = df['list'].apply(pd.Series)\ndf['list'] = df['list'].apply(pd.Series)\ndf['list'] = df['list'].apply(pd.Series)\ndf['list'] = df['list'].apply(pd.Series)\ndf	1
"""Call a base class's class method `do` from derived class `Derived`"""	\nDerived.do()\n\n	Derived.do()\n\n	1
"""find intersection data between series `s1` and series `s2`"""	\ns1.intersection(s2)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n\nA:\n\nYou can use pandas.Series.intersection with a list of Series as the argument:\ns1.intersection(s2, axis=0)\n	pd.merge(s1, s2, on='id', how='inner')\n\n	1
"""prepend the line '#test firstline\n' to the contents of file 'infile' and save as the file 'outfile'"""	\nwith open('infile', 'w') as f:\n    f.write('#test firstline\n')\noutfile = open('outfile', 'w')\noutfile.write('#test secondline\n')\noutfile.close()\n\nprint(infile.read())\n	    infile = 'infile'\n\n    outfile = 'outfile'\n\n    with open(infile, 'r') as f:\n\n        lines = f.readlines()\n\n    with open(outfile, 'w') as f:\n\n        f.write('#test firstline\n')\n\n        f.writelines(lines)\n	0
"""capture final output of a chain of system commands `ps -ef | grep something | wc -l`"""	\nprint('\n'.join(map(str, ps.communicate())))\n	\nimport subprocess\nsubprocess.Popen(["ps", "-ef", "|", "grep", "something"], stdout=subprocess.PIPE).communicate()[0]\nsubprocess.Popen(["ps", "-ef", "|", "grep", "something"], stdout=subprocess.PIPE).communicate()[0]\nsubprocess.Popen(["ps", "-ef", "|", "grep", "something"], stdout=subprocess.PIPE).communicate()[0]\nsubprocess.Popen(	0
"""call multiple bash function ‘vasp’ and ‘tee tee_output’ using ‘|’"""	\nimport os\nimport sys\n	\nimport subprocess\nsubprocess.call(['vasp', 'tee', 'tee_output'])\nsubprocess.call(['vasp', 'tee', 'tee_output'])\nsubprocess.call(['vasp', 'tee', 'tee_output'])\nsubprocess.call(['vasp', 'tee', 'tee_output'])\nsubprocess.call(['vasp', 'tee', 'tee_output'])\nsubprocess.call(['vasp', 'tee', 'tee_output	0
"""How do I sum the first value in each tuple in a list of tuples in Python?"""	\nsum(x[0] for x in list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(zip(*list(	\nsum(x[0] for x in list_of_tuples)\n\n	0
loop over files	    for filename in os.listdir('.'):\n\n        print(filename)\n	\nfor (dirpath, dirnames, filenames) in os.walk('.'):\n    pass\n	0
"""loop over a list `mylist` if sublists length equals 3"""\n   	[x for x in mylist if len(x) == 3]\n\n	\nfor i in range(len(mylist)):\n    if len(mylist[i]) == 3:\n        print(mylist[i])\n        break\n    else:\n        continue\nelse:\n    print("No sublists of length 3")\nprint("Done")\n\n	1
"""find the first element of the tuple with the maximum second element in a list of tuples `lis`"""	\nmax(lis, key=lambda x: x[1])[0]\n\n	    lis = [(1, 2), (3, 4), (5, 6)]\n\n    print(max(lis, key=lambda x: x[1]))\n	0
"""get an absolute file path of file 'mydir/myfile.txt'"""	\nos.path.abspath('mydir/myfile.txt')\n\n	\nos.path.abspath('mydir/myfile.txt')\n\nA:\n\nos.path.abspath('mydir/myfile.txt')\n\nThis will return the absolute path of the file'mydir/myfile.txt' in the current directory.\n\nA:\n\nos.path.abspath('mydir/myfile.txt')\n\nThis will return the absolute path of the file'mydir/myfile.txt' in the current directory.\n\nA:\n\nos.path.abspath('mydir/	0
"""convert tuple of tuples `(('aa',), ('bb',), ('cc',))` to tuple"""	\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple, tup))\ntuple(map(tuple	\n[x[0] for x in list(zip(*[('aa',), ('bb',), ('cc',)]))]\n	1
"""extract ip address from an html string"""	\nre.findall('[0-9]+(?:\.[0-9]+){3}', html)\n\n	\nhtml_string.split('<a href="http://www.google.com">')[0].split('</a>')[1]\n\nprint(html_string.split('<a href="http://www.google.com">')[0].split('</a>')[1])\n\nOutput:\n['http://www.google.com']\n\n	1
"""reverse a priority queue `q` in python without using classes"""	\nq.reverse()\nq.reverse()[::-1]\nq.reverse()[::-1]()\nq.reverse()[::-1]()()\nq.reverse()[::-1]()()()\nq.reverse()[::-1]()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()	\nq.reverse()\n\nprint(q.pop())\n	1
"""unzip list `original`"""\n   	zip(*original)\n\n	\n[x for y in original for x in y]\n\n	1
"""read keyboard-input"""	\nkeyboard_input = raw_input('Keyboard input: ')\nprint(keyboard_input)\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x.lower() for x in keyboard_input.split()]\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x.lower() for x in keyboard_input.split()]\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x	\nimport sys\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline	1
"""reverse the keys and values in a dictionary `myDictionary`"""	\nmyDictionary.items()[::-1].reverse()\n\nA:\n\nYou can use list comprehension to do it:\n[(k, v) for k, v in myDictionary.items()]\n\nor\n[(k, v) for k, v in sorted(myDictionary.items())]\n\nor\n[(k, v) for k, v in sorted(myDictionary.items(), key=lambda x: x[1])]\n\nor\n[(k, v) for k, v in sorted(myDictionary.items(),	\ndict(zip(myDictionary.values(), myDictionary.keys()))\nmyDictionary = dict(zip(myDictionary.values(), myDictionary.keys()))\nmyDictionary = dict(zip(myDictionary.values(), myDictionary.keys()))\nmyDictionary = dict(zip(myDictionary.values(), myDictionary.keys()))\nmyDictionary = dict(zip(myDictionary.values(), myDictionary.keys()))\nmyDictionary = dict(zip(myDictionary.values(), myDictionary.keys()))	1
Python Pandas: Get index of rows which column matches certain value	    import numpy as np\n\n    arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n    print(arr[arr[:, 1] == 2])\n\n    print(arr[arr[:, 1] == 2].shape)\n\n    print(arr[arr[:, 1] == 2].shape[0])\n\n    print(arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1])\n\n    print(arr[arr[:, 1] == 2].shape[0] * arr[arr[:, 1] == 2].shape[1\n	\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf.loc[df['BoolCol'].eq(True),:]\n\ndf	1
"""Convert  DateTime column 'date' of pandas dataframe 'df' to ordinal"""	\ndf['date'].apply(lambda x: x.toordinal())\ndf['date'] = df['date'].apply(lambda x: x.toordinal())\n\ndf['date'] = df['date'].apply(lambda x: datetime.datetime.fromordinal(x))\ndf['date'] = df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\ndf['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, '	\ndf['date'] = pd.to_datetime(df['date'], errors='coerce').dt.dayofyear\ndf['date'] = df['date'].astype(int)\ndf['date'] = df['date'].astype(str)\ndf['date'] = df['date'].astype(int)\ndf['date'] = df['date'].astype(str)\ndf['date'] = df['date'].astype(int)\ndf['date'] = df['date'].astype(str)\ndf	1
"""How to convert a string from CP-1251 to UTF-8?"""	\nimport codecs\nprint(codecs.decode('CP-1251', 'utf-8'))\n	\nimport codecs\ncodecs.decode('\xc2\xa3', 'cp1251')\ncodecs.decode('\xc2\xa3', 'utf-8')\ncodecs.encode('\xc2\xa3', 'cp1251')\ncodecs.encode('\xc2\xa3', 'utf-8')\ncodecs.encode('\xc2\xa3', 'cp1251').decode('cp1251')\ncodecs.encode('\xc2\xa3', 'utf	1
"""Iterate ove list `[1, 2, 3]` using list comprehension"""	\n[x for x in [1, 2, 3]]"""\n[1, 2, 3]"""\n\n	[x for x in [1, 2, 3]]\n\n	1
"""How do I sort a list of dictionaries by values of the dictionary in Python?"""	\nsorted(my_dict.items(), key=lambda x: x[1])\nsorted(my_dict.values(), key=lambda x: x[1])\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.values(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True, key=lambda x: x[0])\nsorted(my_dict.values(), key=	sorted(l, key=lambda x: x['name'], reverse=True)\n\n	1
Python -Remove Time from Datetime String	    when = "2020-01-01T00:00:00.000Z"\n\n    print(when[:10])\n	datetime.datetime.strptime('2013-12-12', '%Y-%m-%d').date()\n\n	1
"""load data containing `utf-8` from file `new.txt` into numpy array `arr`"""	\narr = np.loadtxt('new.txt', delimiter=',', skiprows=1, dtype=None)\n\narr = np.array(arr)\n\narr = np.array(arr, dtype=None)\n\narr = np.array(arr, dtype=None)\n\narr = np.array(arr, dtype=None)\n\narr = np.array(arr, dtype=None)\n\narr = np.array(arr, dtype=None)\n\narr = np.array(arr, dtype=None)\n	\narr = np.loadtxt('new.txt', dtype=np.float32)\narr.shape\narr.dtype\narr[0]\narr[1]\narr[2]\narr[3]\narr[4]\narr[5]\narr[6]\narr[7]\narr[8]\narr[9]\narr[10]\narr[11]\narr[12]\narr[13]\narr[14]\narr[15]\narr[16]\narr[17]\narr[18]\narr[19	0
"""subscript text 'H20' with '2' as subscripted in matplotlib labels for arrays 'x' and 'y'."""	\nax.set_xticklabels(['H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H20', 'H	\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.arange(0, 2, 0.01)\ny = np.exp(-x**2)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('title')\nplt.show()\nplt.savefig('filename.png')\nplt.close()\nplt.savefig('filename.png', bbox_inches='tight')\nplt.close()\n	1
How do you extract a url from a string using python?	    myString = "https://www.google.com"\n\n    print(myString.split("/")[2])\n	\nimport urllib\nmyString = "http://www.example.com/my_page.html"\nmyUrl = urllib.quote(myString)\nprint(myUrl)                                                                                     	1
Append elements of a set to a list in Python	    mySet = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\n    myList = []\n\n    for i in mySet:\n\n        myList.append(i)\n\n    print(myList)\n	\na = [1, 2, 3]\nb = [4, 5, 6]\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)\na\na.extend(b)	0
"""get an array of the mean of each two consecutive values in numpy array `x`"""	\nimport numpy as np\nmean_array = np.mean(x, axis=1)\nmean_array = np.insert(mean_array, 0, x[0])\nmean_array = np.insert(mean_array, len(mean_array), x[-1])\nmean_array = np.insert(mean_array, 0, x[0])\nmean_array = np.insert(mean_array, len(mean_array), x[-1])\nmean_array = np.insert(mean_array, 0, x[0])\nmean	np.mean(np.array([x[i] + x[i + 1] for i in range(len(x) - 1)]), axis=0)\n\n	1
"""find all words in a string `mystring` that start with the `$` sign"""\n   	re.findall('\\$[^$]*', mystring)\n\n	\nimport re\nmystring = '$this is a $string'\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\w+', mystring)\nre.findall(r'\$\	1
"""add one to the hidden web element with id 'XYZ' with selenium python script"""	\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()\ndriver.find_element_by_id('XYZ').click()	\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\ndriver = webdriver.Firefox()\ndriver.get("http://www.google.com")\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL)\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL)\ndriver.find_element_by_id("XYZ").send_keys(Keys.CONTROL)\ndriver.find_element_by_id("XY	1
"""Remove all strings from a list a strings `sents` where the values starts with `@$\t` or `#`"""	\nsents = [s for s in sents if s.startswith('@$\t') or s.startswith('#')]\nprint(sents)\n\nOutput:\n['@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$\t', '#', '@$	\nsents = [sent for sent in sents if not sent.startswith("@$")]\nsents = [sent for sent in sents if not sent.startswith("#	1
"""add an entry 'wuggah' at the beginning of list `myList`"""	\nmyList = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nmyList = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, wuggah]\nmyList = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, wuggah]\nmyList = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, wuggah]\nmyList = [1, 2, 3, 4, 5, 6	myList.insert(0, 'wuggah')\n\n	1
"""find all matches of regex pattern '([a-fA-F\\d]{32})' in string `data`"""	\nre.findall('([a-fA-F\\d]{32})', data)\n\nprint(re.findall('([a-fA-F\\d]{32})', 'a b c d e f g h i j k l m n o p q r s t u v w x y z')[0])\n\nOutput:\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m', 'n', 'o', 'p	    data = """\n\n    This is a multi-line string.\n\n    It is split into separate strings.\n\n    print(re.findall(r'([a-fA-F\d]{32})', data))\n	1
"""Put the curser at beginning of the file"""	\nfile.seek(0)\n\n	\nimport os\nos.chdir('/path/to/your/file')\nos.startfile('yourfile.txt')\nos.chdir('/path/to/your/file')\nos.startfile('yourfile.txt')\nos.chdir('/path/to/your/file')\nos.startfile('yourfile.txt')\nos.chdir('/path/to/your/file')\nos.startfile('yourfile.txt')\nos.chdir('/path/to/your/file')\nos.startfile('	0
"""check if object `o` is a string"""	\nisinstance(o, str)\n\n	isinstance(obj_to_test, str)\n\n	1
"""replace all occurences of newlines `\n` with `<br>` in dataframe `df`"""	\ndf.replace('\n', '<br>')\n\ndf\n\nOutput:\n                                                                                                           	\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '<br>', regex=True)\ndf.replace('\n', '	0
"""get a list of all keys in Cassandra database `cf` with pycassa"""	\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnFamilyDescriptor\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnDescriptor\nfrom pycassa.system.ttypes import ColumnDescript	\nfrom cassandra.cluster import Cluster\ncluster = Cluster(['127.0.0.1'])\ncluster.connect()\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show keyspace')\ncluster.execute('show	1
Combining two numpy arrays to form an array with the largest value from each array	    import numpy as np\n\n    arr1 = np.array([2, 3, 4])\n\n    arr2 = np.array([1, 5, 2])\n\n    print(np.maximum(arr1, arr2))\n	\nnp.maximum(np.arange(len(a)), np.arange(len(b)))\n\n[2, 3, 4]\n[1, 5, 2]\n\n	0
"""argparse add argument with flag '--version' and version action of '%(prog)s 2.0' to parser `parser`"""\n   	parser.add_argument('--version', action='version', version='%(prog)s 2.0')\n\n	\nparser.add_argument('--version', action='store_true', default=False, help='Show version information')\nparser.parse_args(['--version'])\nprint(parser.version)\n\nA:\n\nYou can use argparse.ArgumentParser.add_argument() to add an argument to the parser:\nparser.add_argument('--version', action='store_true', default=False, help='Show version information')\nparser.parse_args(['--version'])\n	0
"""separate words delimited by one or more spaces into a list"""	\nimport re\nre.split(r'\s+', 'one two three')\nre.split(r'\s+', 'one two three')[0]\nre.split(r'\s+', 'one two three')[1]\nre.split(r'\s+', 'one two three')[2]\nre.split(r'\s+', 'one two three')[3]\nre.split(r'\s+', 'one two three')[4]\nre.split(r'\s+', 'one two	\n[word.split(' ') for word in list(word.split(' '))]\n\nprint(list(word.split(' ')))\n\nOutput:\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m', 'n', 'o', 'p', 'q', 'r','s', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n\n	0
"""python regex  to find all numbers and dots from 'text'"""	\nimport re\ntext = "one two three four five six seven eight nine"\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\d+', text)\nre.findall(r'\	\nimport re\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text)\nre.findall(r'\d+\.\d+', text	1
"""create a datetime with the current date & time"""	\ndatetime.datetime.now() + datetime.timedelta(days=1)\ndatetime.datetime.now() + datetime.timedelta(days=1) + datetime.timedelta(days=1)\ndatetime.datetime.now() + datetime.timedelta(days=1) + datetime.timedelta(days=1) + datetime.timedelta(days=1) + datetime.timedelta(days=1)\ndatetime.datetime.now() + datetime.timedelta(	\ndatetime.datetime.now()\n\n	1
"""Python Pandas: How to replace a characters in a column of a dataframe?"""	\ndf.replace(old_string, new_string)\ndf.replace(old_string, new_string, regex=True)\ndf.replace(old_string, new_string, regex=False)\ndf.replace(old_string, new_string, regex=None)\ndf.replace(old_string, new_string, regex=None, inplace=True)\ndf.replace(old_string, new_string, regex=None, inplace=False)\ndf.replace(old_string, new_string, regex=None, inplace=	df['column_name'].str.replace('a', 'b')\n\n	1
"""Removing duplicates in list `t`"""	\nt.pop()\n\nprint(t)\n\nOutput:\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n	list(set(abracadabra))\n\n	1
"""average each two columns of array `data`"""	\ndata.mean(axis=1)\n\n	np.mean(data, axis=1)\n\n	0
"""copy all values in a column 'B' to a new column 'D' in a pandas data frame 'df'"""	\ndf['B'] = df['B'].apply(lambda x: x.replace(',',''))\ndf['D'] = df['B'].apply(lambda x: x.replace(',',''))\ndf\ndf.to_csv('new_file.csv', index=False)\ndf.to_csv('new_file.csv', index=False)\ndf.to_csv('new_file.csv', index=False)\ndf.to_csv('new_file.csv', index=False)\ndf.to_csv('new_file	df['D'] = df['B']\n\n	1
"""Find all numbers and dots from a string `text` using regex"""	\nre.findall('\\d+\\.\\d+', text)\n\nThis will return a list of numbers and dots separated by a comma.\n\n	\nimport re\ntext = "123.456.789.123"\nre.findall(r'\d+\.\d+\.\d+\.\d+', text)\nre.findall(r'\d+\.\d+\.\d+\.\d+', text)\nre.findall(r'\d+\.\d+\.\d+\.\d+', text)\nre.findall(r'\d+\.\d+\.\d+\.\d+', text)\nre.findall(r'\	1
python's re: return True if regex contains in the string	    foobarrrr = "foobarrrr"\n\n    print(re.search("ba[rzd]", foobarrrr))\n	re.search('ba[rzd]', 'foobarrrr')\n\n	1
"""sort list `li` in descending order based on the date value in second element of each list in list `li`"""\n   	li.sort(key=lambda x: x[1], reverse=True)\n\n	\nsorted(li, key=lambda x: x[1], reverse=True)\n\n	1
"""open a 'gnome' terminal from python script and run  'sudo apt-get update' command."""	\nimport subprocess\nsubprocess.call(['gnome-terminal', '--disable-factory', '--disable-factory-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable-extensions', '--disable	\nos.system('gnome')\nos.system('sudo apt-get update')\n\n	1
"""find maximal value in matrix `matrix`"""\n   	max(matrix.max(), matrix.min())\n\n	\nmax(matrix)\n\n	1
"""get rows of dataframe `df` that match regex '(Hel|Just)'"""	\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf.apply(lambda x: x.str.contains('Hel|Just'))\n\ndf	    import pandas as pd\n\n    df = pd.DataFrame({'A': ['Hel', 'lo', 'Just', 'Hi', 'Hel', 'lo', 'Just', 'Hi'],\n\n                       'B': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']})\n\n    print(df.query('A.str.contains("Hel|Just")'))\n\n    print(df.query('A.str.contains("Hel|Just")').A)\n\n    print(df.query('A.str.contains("Hel|Just")').B)\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|"))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(0))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(1))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(0).str.split(""))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(0).str.split("").str.get(0))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(0).str.split("").str.get(1))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(1).str.split(""))\n\n    print(df.query('A.str.contains("Hel|Just")').A.str.split("|").str.get(1).str.split("").str.get(0))\n\n    print(df\n	1
"""get the index of an integer `1` from a list `lst` if the list also contains boolean items"""	\ndef index_of_1(lst):\n    for i, x in enumerate(lst):\n        if x == 1:\n            return i\n    return None\nprint(index_of_1([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,	\n[x for x in lst if x[1] == 1]\n\nprint(lst)\n\nOutput:\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n	1
"""replace spaces with underscore"""\n   	re.sub(' ', '_', 'hello')\n\n	\nre.sub(' +', '_', string)\n\n	1
"""split a string into a list of words and whitespace"""	\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in	\n[word.split() for word in string.split()]\n\nprint(list(re.split(' ','')))\n\nOutput:\n['one', 'two', 'three', 'four', 'five','six','seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen','sixteen','seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',	1
"""display the float `1/3*100` as a percentage"""	\nprint('{0:.2f}'.format(1/3*100))\n\nA:\n\nYou can use float() to convert a float to a string:\n	    print(str(round(1/3*100, 2)) + "%")\n	1
"""remove key 'c' from dictionary `d`"""	\nd = {'a':1, 'b':2, 'c':3}\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\nd.pop('c')\nd\n	    def func(d):\n\n        del d['c']\n\n        return d\n\n    return func\n	0
"""scatter a plot with x, y position of `np.random.randn(100)` and face color equal to none"""	\nplt.scatter(np.random.randn(100), np.random.randn(100), c='none', s=0)\nplt.show()\n\nA:\n\nYou can use plt.scatter(x, y, c='none', s=0) to plot a scatter plot with x and y as the x and y coordinates of a random point in a 2D array.\nThe s parameter is used to specify the color of the points.\n\nA:\n\nYou can use plt.scatter(np.random.randn(100	\nplt.scatter(np.random.randn(100), np.random.randn(100), c=None)\nplt.show()\n\n	1
"""Create 3d array of zeroes of size `(3,3,3)`"""	\nnp.zeros((3, 3, 3))\n\n	\nimport numpy as np\na = np.zeros((3,3,3))\na[:,:,:3] = np.zeros((3,3,3))\na[:,:,:,3] = np.zeros((3,3,3))\na[:,:,:,:,3] = np.zeros((3,3,3))\na[:,:,:,:,:,3] = np.zeros((3,3,3))\na[:,:,:,:,:,:,3] = np.zeros((3,3,3))\na	1
"""Calculate sum over all rows of 2D numpy array"""\n   	np.sum(a, axis=1)\n\n	\nsum(a[:, 0] for a in b)\n\n	1
How to get a 16bit Unsigned integer in python	    print(int(input("Enter an integer: ")))\n	\nnumber = int(number)\n\nprint(number)\n\nA:\n\nYou can use int(number) to convert number to int and assign it to variable number.\nnumber = int(number)\nnumber = number + 1\n	1
"""get list of values from dictionary 'mydict' w.r.t. list of keys 'mykeys'"""	\nmydict = {'key1': 'value1', 'key2': 'value2'}\nmykeys = ['key1', 'key2']\nmyvalues = [mydict[key] for key in mykeys]\nprint(myvalues)\n	    mydict = {"a": 1, "b": 2, "c": 3}\n\n    mykeys = ["a", "b", "c"]\n\n    print(list(map(lambda x: mydict[x], mykeys)))\n	0
"""insert `_suff` before the file extension in `long.file.name.jpg` or replace `_a` with `suff` if it precedes the extension."""	\nlong.file.name.jpg.replace('_a', '_suff', 1)\n\n	\nfrom django.conf import settings\nfrom django.core.files.storage import default_storage\nfrom django.core.files.base import ContentFile\nfrom django.core.files.storage import default_storage\nfrom django.core.files.base import ContentFile\nfrom django.core.files.storage import default_storage\nfrom django.core.files.base import ContentFile\nfrom django.core.files.storage import default_storage\nfrom django.core.files.base import ContentFile\nfrom django.core.files.storage import default	0
"""download a file `url` over HTTP"""	\nurllib.request.urlretrieve(url, 'file.txt')\n\nA:\n\nYou can use urllib2.urlopen to download a file from a url:\nimport urllib2\nurllib2.urlopen('http://www.google.com')\n\nor urllib.request.urlretrieve('http://www.google.com')\n\nA:\n\nYou can use urllib.request.urlretrieve() to download a file from a url.\nurl = 'http://www.google.com'\nurll	\nimport urllib2\nurllib2.urlretrieve('http://www.example.com/', 'file.txt')\nurllib2.urlretrieve('http://www.example.com/', 'file.txt')\nurllib2.urlretrieve('http://www.example.com/', 'file.txt')\nurllib2.urlretrieve('http://www.example.com/', 'file.txt')\nurllib2.urlretrieve('http://www.example.com/', 'file.txt')\nur	0
"""joining data from dataframe `df1` with data from dataframe `df2` based on matching values of column 'Date_Time' in both dataframes"""	\ndf1['Date_Time'] = df1['Date_Time'].dt.date\ndf2['Date_Time'] = df2['Date_Time'].dt.date\ndf1['Date_Time'] = df1['Date_Time'].dt.date\ndf2['Date_Time'] = df2['Date_Time'].dt.date\ndf1['Date_Time'] = df1['Date_Time'].dt.date\ndf2['Date_Time'] = df2['Date_Time'].dt.date\ndf1['Date_Time']	pd.merge(df1, df2, on='Date_Time')\n\n	1
"""split a string into a list of words and whitespace"""	\n[x.strip() for x in re.split('\\W+', 'a b c d e f g h i j k l m n o p q r s t u v w x y z')]\n	\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in words]\nwords = [word.split() for word in	0
"""write dataframe `df`, excluding index, to a csv file"""	\ndf.to_csv('path/to/file.csv', index=False)\ndf.to_csv('path/to/file.csv', index=False, header=False)\ndf.to_csv('path/to/file.csv', index=False, header=False, mode='a')\ndf.to_csv('path/to/file.csv', index=False, header=False, mode='a', mode='a')\ndf.to_csv('path/to/file.csv', index=False, header=False, mode='a', mode	\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n\ndf.to_csv('test.csv', index=False)\n	1
"""open a file `Output.txt` in append mode"""	\nopen('Output.txt', 'a')\n\n	\nwith open('Output.txt', 'a') as f:\n    f.write(str(data))\n    f.write('\n')\n    f.close()\n    f = open('Output.txt', 'r')\n    print(f.read())\n    f.close()\n    f = open('Output.txt', 'w')\n    f.write(str(data))\n    f.close()\n    f = open('Output.txt', 'r')\n    print(f.read())\n    f.close()\n    f = open('	0
"""remove symbols from a string `s`"""	\ns = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\ns = ''.join(c for c in s if c not in '!@#$%^&*()_+{}|:"<>?/.,;')\ns\ns = ''.join(c for c in s if c not in '!@#$%^&*()_+{}|:"<>?/.,;')\ns\ns = ''.join(c for c in s if c not in '	\ns.replace('\\', '')\n\nprint(s)\n\nOutput:\n\n'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\	1
"""concatenate elements of list `b` by a colon ":""""\n   	print(':'.join(b))\n\n	\nb = [1, 2, 3]\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(["a", "b", "c"])\nb.extend(	0
"""remove escape character from string "\\a""""	\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\a", "")\ns = s.replace("\\	\nprint(s.replace("\\a", ""))\n	1
How to get the filename without the extension from a path in Python?	    import os\n\n    def func(filename):\n\n        return os.path.splitext(filename)[0]\n\n    return func\n	\nos.path.splitext('hemanth.txt')[0]\n\n	1
"""erase all the contents of a file `filename`"""\n   	open(filename, 'w').close()\n\n	    filename = input("Enter a filename: ")\n\n    try:\n\n        f = open(filename, "w")\n\n        f.close()\n\n    except FileNotFoundError:\n\n        print("File not found")\n\n    except PermissionError:\n\n        print("Permission denied")\n\n    else:\n\n        print("File erased")\n\n    finally:\n\n        print("Program finished")\n	1
"""get a list of all keys in Cassandra database `cf` with pycassa"""	\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT * FROM cf')\ncqlsh.execute('SELECT	    import pycassa\n\n    from pycassa.pool import ConnectionPool\n\n    from pycassa.columnfamily import ColumnFamily\n\n    pool = ConnectionPool('Keyspace1')\n\n    cf = ColumnFamily(pool, 'Standard1')\n\n    keys = cf.get_range()\n\n    for key in keys:\n\n        print(key)\n	1
"""How do I sort a list of dictionaries by values of the dictionary in Python?"""	\nsorted(my_dict.items(), key=lambda x: x[1])\nsorted(my_dict.values(), key=lambda x: x[1])\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.values(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True, key=lambda x: x[0])\nsorted(my_dict.values(), key=	\nsorted(my_dict.items(), key=lambda x: x[1])\nsorted(my_dict.values(), key=lambda x: x[1])\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.values(), key=lambda x: x[1], reverse=True)\nsorted(my_dict.items(), key=lambda x: x[1], reverse=True, key=lambda x: x[0])\nsorted(my_dict.values(), key=	1
"""replace spaces with underscore"""	\nre.sub(' +', '_', string)\n\n	\nre.sub('\\s+', '_', '_')\n\nprint(re.sub('\\s+', '_', '_'))\n	0
"""find 10 largest differences between each respective elements of list `l1` and list `l2`"""	\ndef largest_difference(l1, l2):\n    return max([abs(l1[i] - l2[i]) for i in range(len(l1))])\nl1 = [1, 2, 3, 4, 5]\nl2 = [2, 3, 4, 5, 6]\nlargest_difference(l1, l2)\nlargest_difference(l2, l1)\nlargest_difference(l1, l2)\nlargest_difference(l2, l1)\nlargest_difference(l1	sorted(list(map(lambda x, y: abs(x - y), l1, l2)))[:10]\n\n	1
"""replace each 'a' with 'b' and each 'b' with 'a' in the string 'obama' in a single pass."""\n   	re.sub('a', 'b', 'obama')\n\n	    print("obama".replace("a", "b").replace("b", "a"))\n	1
"""Calculate sum over all rows of 2D numpy array"""	\nsum(a[:, 0] for a in b)\n\n	\nnp.sum(np.arange(len(a)) * np.arange(len(b)), axis=0)\n\nThis is a 2D numpy array with shape (3, 3) and each row is a list of lists of length 3.\na = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nb = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nnp.sum(np.arange(len(	0
"""click a href button with text 'Send InMail' with selenium"""	\ndriver.find_element_by_link_text('Send in mail').click()\n\n	driver.find_element_by_xpath('//*[@id="send"]').click()\n\n	0
"""find the string in `your_string` between two special characters "[" and "]""""	\nyour_string.find('[', 2)\nyour_string.find(']', 2)\n	\nre.findall('\\[.*\\]', your_string)\n\n	1
"""Convert unix timestamp '1347517370' to formatted string '%Y-%m-%d %H:%M:%S'"""	\nimport datetime\ndatetime.datetime.fromtimestamp(1347517370)\ndatetime.datetime.fromtimestamp(1347517370).strftime('%Y-%m-%d %H:%M:%S')\ndatetime.datetime.fromtimestamp(1347517370).strftime('%Y-%m-%d %H:%M:%S')\ndatetime.datetime.fromtimestamp(1347517370).strftime('%Y-%m-%d %H:%M:%S')	\n'%Y-%m-%d %H:%M:%S' % (1347517370,)\n\n	0
"""write `newFileBytes` to a binary file `newFile`"""	\nwith open('newFile', 'wb') as f:\n    f.write(newFileBytes)\nwith open('newFile', 'rb') as f:\n    f.read(newFileBytes)\nwith open('newFile', 'rb') as f:\n    f.read(newFileBytes)\nwith open('newFile', 'rb') as f:\n    f.read(newFileBytes)\nwith open('newFile', 'rb') as f:\n    f.read(newFileBytes)\nwith open	\nnewFile.write(newFileBytes)\nnewFile.close()\n\n	1
Download file from web in Python 3	    import requests\n\n    url = input("Enter the url: ")\n\n    file_name = input("Enter the file name: ")\n\n    r = requests.get(url)\n\n    with open(file_name, 'wb') as f:\n\n        f.write(r.content)\n\n    print("Downloaded successfully!")\n\n    return r.status_code\n	\ndownload_file(url, file_name)\n\n	1
"""write the elements of list `lines` concatenated by special character '\n' to file `myfile`"""\n   	myfile.write('\n'.join(lines))\n\n	\nfor line in lines:\n    myfile.write(line + '\n')\nmyfile.close()\n\n	1
"""identify duplicate values in list `mylist`"""	\nmylist.sort(key=lambda x: x[1])\n\nprint(mylist)\n\nOutput:\n[('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', 'b'), ('a', '	[x for x, y in itertools.groupby(mylist, lambda x: x)]\n\n	1
"""make a barplot of data in column `group` of dataframe `df` colour-coded according to list `color`"""	\ndf.groupby('group').mean()['value'].plot(kind='bar', color=color)\ndf.groupby('group').mean()['value'].plot(kind='bar', color=color)\ndf.groupby('group').mean()['value'].plot(kind='bar', color=color)\ndf.groupby('group').mean()['value'].plot(kind='bar', color=color)\ndf.groupby('group').mean()['value'].plot(kind='bar', color=color)\ndf.groupby('group').	\nplt.bar(df.group, df.group, color=color)\nplt.show()\n\n	1
"""Sorting data in DataFrame Pandas"""	\ndf.sort_values(by=['col1','col2'], ascending=False)\ndf.sort_values(by=['col1','col2'], ascending=True)\ndf.sort_values(by=['col1','col2'], ascending=False, inplace=True)\ndf.sort_values(by=['col1','col2'], ascending=False, inplace=True, axis=1)\ndf.sort_values(by=['col1','col2'], ascending=False, inplace=True, axis=1,	\ndf.sort_values(by=['column_name'], ascending=False)\ndf.sort_values(by=['column_name'], ascending=True)\ndf.sort_values(by=['column_name'], ascending=False, inplace=True)\ndf.sort_values(by=['column_name'], ascending=True, inplace=True)\ndf.sort_values(by=['column_name'], ascending=False, inplace=True)\ndf.sort_values(by=['column_name'], ascending=True	1
"""split string `text` by ",""""	\ntext = 'Hello, world!'\ntext.split(',')\n['Hello', 'world!']\ntext.split(',')[0]\n'Hello'\ntext.split(',')[1]\n'world!'\ntext.split(',')[2]\n'!'\ntext.split(',')[3]\n'world!'\ntext.split(',')[4]\n'!'\ntext.split(',')[5]\n'world!'\ntext.split(',')[6]\n'!'\ntext.split(',')[7]	re.split('\\,\\s+', text)\n\n	1
Open file in Python	    with open('path', 'r') as f:\n\n        print(f.read())\n\n    return True\n	\nwith open(path, 'r') as f:\n    f.read()\n    f.close()\n    f.closed\n    f.mode\n    f.name\n    f.encoding\n    f.newlines\n    f.softspace\n    f.tell()\n    f.seek(0)\n    f.read()\n    f.readline()\n    f.readlines()\n    f.readlines()[1]\n    f.readlines()[1]\n    f.readlines()[1]\n    f.readlines()	0
"""Print new line character as `\n` in a string `foo\nbar`"""\n   	print('foo\nbar')\n\n	\nprint('foo\nbar')\n	1
"""get a list containing the sum of each element `i` in list `l` plus the previous elements"""	\nsum(i for i in l if i - 1) + sum(i for i in l if i - 2)\n	\nl = [1, 2, 3, 4, 5]\nsum(l[i] + l[i-1] for i in range(1, len(l)))\nsum(l[i] + l[i-1] for i in range(2, len(l)))\nsum(l[i] + l[i-1] for i in range(3, len(l)))\nsum(l[i] + l[i-1] for i in range(4, len(l)))\nsum(l[i] + l[i-1]	1
Attribute getters in python	    def func(obj, attr):\n\n        return getattr(obj, attr)\n\n    return func\n	\nobj.attr\nobj.attr\nobj.attr.attr\nobj.attr.attr.attr\nobj.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr.attr.attr.attr.attr\nobj.attr.attr.attr.attr.attr.attr.attr	0
"""How can I parse a time string containing milliseconds in it with python?"""	\ntime.strptime('12:00:00', '%H:%M:%S')\n\n	\nimport datetime\ndatetime.datetime.strptime('00:00:00', '%H:%M:%S')\ndatetime.datetime.strptime('00:00:00', '%H:%M:%S.%f')\ndatetime.datetime.strptime('00:00:00', '%H:%M:%S.%f.%f')\ndatetime.datetime.strptime('00:00:00', '%H:%M:%S.%f.%f.%	1
"""create a datetime with the current date & time"""	\ndatetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\nA:\n\ndatetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\nA:\n\ndatetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\nA:\n\ndatetime.datetime.now().strftime('%Y-%m-%d %H:%M:	datetime.datetime.now()\n\n	1
"""sum all elements of nested list `L`"""	\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum(sum(L, []))\nsum	\nsum(map(sum, L))\n\n	1
"""remove a div with a id `main-content` using beautifulsoup"""\n   	soup.find('div', id='main-content')\nsoup.find('div', id='main-content').decompose()\n	\nimport bs4\nbs_html = bs4.BeautifulSoup(html)\nbs_html.find('div', id='main-content')\nbs_html.find('div', id='main-content').decompose()\nbs_html.find('div', id='main-content')\nbs_html.find('div', id='main-content').decompose()\nbs_html.find('div', id='main-content')\nbs_html.find('div', id='main-content').decompose()\nbs_html.	0
"""append list `a` to `c`"""	\nc.extend(a)\n\n	c.append(a)\n\n	0
"""read keyboard-input"""	\nkeyboard_input = raw_input('Keyboard input: ')\nprint(keyboard_input)\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x.lower() for x in keyboard_input.split()]\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x.lower() for x in keyboard_input.split()]\n\nA:\n\nYou can use a list comprehension to get the key pressed:\nkeyboard_input = [x	\nimport sys\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline()\nsys.stdin.readline	0
"""return `True` if string `foobarrrr` contains regex `ba[rzd]`"""	\nre.search('ba[rzd]', foobarrrr) is None\n\n	    foobarrrr = "foobarrrr"\n\n    print(re.search("ba[rzd]", foobarrrr))\n	1
