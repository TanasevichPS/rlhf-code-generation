{
  "model": {
    "base_model_name": "microsoft/CodeGPT-small-py",
    "reward_model_name": "microsoft/codebert-base",
    "policy_model_size": "small",
    "reward_model_size": "base",
    "trust_remote_code": true,
    "use_fast_tokenizer": true,
    "torch_dtype": "float16",
    "max_position_embeddings": 1024,
    "hidden_size": 768,
    "num_attention_heads": 12,
    "num_hidden_layers": 12
  },
  "training": {
    "learning_rate": 1e-05,
    "batch_size": 4,
    "gradient_accumulation_steps": 4,
    "max_grad_norm": 1.0,
    "ppo_epochs": 3,
    "ppo_clip_ratio": 0.2,
    "ppo_value_loss_coef": 0.1,
    "ppo_entropy_coef": 0.01,
    "ppo_kl_penalty": 0.02,
    "dpo_beta": 0.1,
    "dpo_loss_type": "sigmoid",
    "warmup_steps": 100,
    "total_steps": 500,
    "save_steps": 500,
    "eval_steps": 100,
    "logging_steps": 10,
    "early_stopping_patience": 3,
    "early_stopping_threshold": 0.01
  },
  "generation": {
    "max_new_tokens": 256,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1,
    "do_sample": false,
    "max_prompt_length": 512,
    "max_response_length": 512,
    "min_code_length": 10,
    "num_beams": 4,
    "num_return_sequences": 1,
    "early_stopping": true
  },
  "reward": {
    "reward_learning_rate": 2e-05,
    "reward_batch_size": 8,
    "reward_epochs": 3,
    "human_feedback_weight": 0.3,
    "use_human_logits": true,
    "human_logits_layer": "last",
    "syntax_reward_weight": 0.2,
    "execution_reward_weight": 0.3,
    "semantic_reward_weight": 0.3,
    "human_preference_weight": 0.2,
    "reward_normalization": true,
    "reward_clipping": true,
    "reward_clip_value": 5.0
  },
  "evaluation": {
    "target_bertscore": 0.7,
    "target_codebleu": 0.6,
    "target_bleu": 0.4,
    "target_rouge": 0.5,
    "target_ruby": 0.3,
    "eval_batch_size": 8,
    "eval_samples": 50,
    "eval_datasets": [
      "T2C-CONALA-CODEGEN-FINETUNED-SO.csv",
      "T2C-CONALA-CODEGEN-VANILLA.csv",
      "T2C-CONALA-CODEGEN2B-FINETUNED-CONALA-IMPORTS.csv"
    ],
    "use_cached_embeddings": true,
    "cache_embeddings": true,
    "embedding_model": "microsoft/codebert-base"
  },
  "data": {
    "train_data_path": "./datasets_for_training",
    "eval_data_path": "./datasets_for_eval",
    "human_feedback_path": "./evaluation_results_server",
    "output_path": "./modern_outputs",
    "conala_local_path": "./conala-corpus",
    "use_model_for_synth_feedback": true,
    "synth_feedback_model_name": "gpt2",
    "max_train_samples": 10000,
    "max_eval_samples": 1000,
    "train_test_split": 0.9,
    "use_data_augmentation": true,
    "augmentation_ratio": 0.1,
    "min_prompt_length": 0,
    "max_prompt_length": 512,
    "min_response_length": 0,
    "max_response_length": 512
  },
  "hardware": {
    "device": "cuda",
    "mixed_precision": true,
    "gradient_checkpointing": true,
    "max_memory_usage": 0.9,
    "offload_to_cpu": false,
    "use_deepspeed": false,
    "local_rank": -1,
    "world_size": 1,
    "ddp_backend": "nccl"
  },
  "seed": 42,
  "debug": false,
  "verbose": true,
  "experiment_name": "modern_rlhf_experiment",
  "run_name": "modern_rlhf_experiment_20251031_142719",
  "tags": [
    "research",
    "experimental"
  ]
}